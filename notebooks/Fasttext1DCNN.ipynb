{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:32.517289Z",
     "start_time": "2020-06-30T17:36:26.743654Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:32.529245Z",
     "start_time": "2020-06-30T17:36:32.519358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:32.538322Z",
     "start_time": "2020-06-30T17:36:32.534220Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_speeds = {\"keyboard\": 117, \"char_substitute\": 109, \"char_insert\": 109, \"char_swap\": 114,\n",
    "              \"ocr\": 114, \"char_delete\": 108,\n",
    "              \"word_insert\": 0.0, \"word_substitute\": 0.0, \"text_rotate\": 32,\n",
    "              \"stopword_insert\": 34, \"word_join\": 32, \"word_cutout\": 36,\n",
    "              \"w2v_insert\": 0.0, \"w2v_substitute\": 0.0, \n",
    "              \"fasttext\": 137, \"glove_twitter\": 88, \"glove_wiki\": 82, \"word2vec\": 137,\n",
    "              \"synonym\": 522, \"split\": 110, \"sentence_shuffle\": 67, \"one_third_cut\": 0.0, \"half_cut\":0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:32.707632Z",
     "start_time": "2020-06-30T17:36:32.539699Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "choice_probas = {\"keyboard\": 0.1, \"char_substitute\": 0.0, \"char_insert\": 0.1, \"char_swap\": 0.1, \"ocr\": 0.0, \"char_delete\": 0.1,\n",
    "                 \"fasttext\": 0.0, \"glove_twitter\": 0.0, \"glove_wiki\": 0.0, \"word2vec\": 0.0, \"split\": 0.1,\n",
    "                 \"stopword_insert\": 0.3, \"word_join\": 0.1, \"word_cutout\": 0.8,\n",
    "                 \"text_rotate\": 0.5, \"sentence_shuffle\": 0.5, \"one_third_cut\": 0.3, \"half_cut\":0.1}\n",
    "preprocess_text = TextAugment([0.05, 0.05, 0.05, 0.35, 0.3, 0.2], choice_probas, fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "\n",
    "im_transform = transforms.RandomChoice([transforms.Grayscale(num_output_channels=3), \n",
    "                                        transforms.RandomHorizontalFlip(p=1.0),\n",
    "                                        lambda x: x,\n",
    "                                        transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224)]),\n",
    "                                        transforms.Compose([transforms.Resize(480), transforms.CenterCrop(400)]),\n",
    "                                        transforms.Compose([transforms.Resize(640), transforms.CenterCrop(520)]),\n",
    "                                        DefinedRotation(15), QuadrantCut()])\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=preprocess_text, train_image_transform=im_transform, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = True, dev=False, \n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=False,)\n",
    "\n",
    "# ImageAugment([0.2, 0.5, 0.3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:33.259447Z",
     "start_time": "2020-06-30T17:36:33.249961Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:36:35.404146Z",
     "start_time": "2020-06-30T17:36:35.400415Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 10\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([11, 13], gamma=0.25) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "augmentation_weights = {\"None\": 1.0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T11:44:54.095758Z",
     "start_time": "2020-05-25T11:27:36.177Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Fasttext 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 512 DIMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T05:28:25.345147Z",
     "start_time": "2020-06-30T05:20:49.452992Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_fn = model_builder(Fasttext1DCNNModel, \n",
    "                         dict(classifier_dims=256, num_classes=2, \n",
    "                              n_layers=2, final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.1, embedding_dims=256, internal_dims=512,\n",
    "                             fasttext_file=\"crawl-300d-2M-subword.bin\", featurizer=\"transformer\",),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[1, 4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lang Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:28:44.793879Z",
     "start_time": "2020-06-30T16:31:08.096228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params = 15501232 \n",
      " LangFeaturesModel(\n",
      "  (spacy_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(282, 256, kernel_size=(1,), stride=(1,), groups=2, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(256, 128, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (crawl_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(600, 384, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(384, 192, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (gensim_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(700, 512, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (full_sent_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(300, 128, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(128, 64, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (key_occ_cnt_pytextrank): Embedding(8, 8)\n",
      "  (key_wc_pytextrank): Embedding(4, 8)\n",
      "  (yake_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(300, 64, kernel_size=(1,), stride=(1,), groups=2, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(64, 32, kernel_size=(1,), stride=(1,), groups=2, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (keyphrase_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(48, 128, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(128, 64, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (tag_em): Embedding(292, 8)\n",
      "  (sw_em): Embedding(2, 8)\n",
      "  (sent_start_em): Embedding(2, 8)\n",
      "  (is_oov_em): Embedding(2, 8)\n",
      "  (has_digit_em): Embedding(2, 8)\n",
      "  (is_mask_em): Embedding(2, 8)\n",
      "  (w_len): Embedding(16, 8)\n",
      "  (wc_emb): Embedding(16, 8)\n",
      "  (key_wc_rake_nltk): Embedding(4, 8)\n",
      "  (nltk_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(350, 384, kernel_size=(1,), stride=(1,), groups=2, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(384, 192, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (contract_nn): ExpandContract(\n",
      "    (nn): Sequential(\n",
      "      (0): Transpose()\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Conv1d(896, 512, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "      (5): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "      (6): Transpose()\n",
      "      (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (featurizer): TransformerFeaturizer(\n",
      "    (input_nn): Linear(in_features=256, out_features=512, bias=False)\n",
      "    (output_nn): Linear(in_features=512, out_features=256, bias=False)\n",
      "    (transformer): Transformer(\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (global_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (final_layer): MultiTaskForward(\n",
      "    (heads): ModuleList(\n",
      "      (0): CNNHead(\n",
      "        (loss): CrossEntropyLoss()\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.1, inplace=False)\n",
      "          (1): Transpose()\n",
      "          (2): Conv1d(256, 2, kernel_size=(16,), stride=(1,), bias=False)\n",
      "          (3): AdaptiveAvgPool1d(output_size=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80873d914c564010b59ec156e352f282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31aaa8ba8b54d0db754a0d8104532d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  1 Loss = 1.294604 LR = 0.00067442\n",
      "Epoch =  1 Train = 0.584293 Val = 0.585680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb15fe627c24c87873832c5022a7ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  2 Loss = 0.771310 LR = 0.00094758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9639aa9dc774730944179ad93f5a709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  3 Loss = 0.766091 LR = 0.00060697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a76471d9f4d018cb68f5b44e3d7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  4 Loss = 0.733809 LR = 0.00018654\n",
      "Epoch =  4 Train = 0.656464 Val = 0.646241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b2c65b3b68440aa3d905cf3fc53c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  5 Loss = 0.708022 LR = 0.00000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_or_std</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mean</th>\n",
       "      <th>map</th>\n",
       "      <td>0.575</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">std</th>\n",
       "      <th>map</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train   val\n",
       "mean_or_std metric               \n",
       "mean        map       0.575 0.546\n",
       "            accuracy  0.469 0.463\n",
       "            auc       0.690 0.672\n",
       "std         map       0.000 0.000\n",
       "            accuracy  0.000 0.000\n",
       "            auc       0.000 0.000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">train</th>\n",
       "      <th colspan=\"4\" halign=\"left\">val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>supoort</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>supoort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.338</td>\n",
       "      <td>4560.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1140.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.556</td>\n",
       "      <td>2640.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.557</td>\n",
       "      <td>660.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train                             val                      \n",
       "    precision recall    f1  supoort precision recall    f1  supoort\n",
       "neg     0.801  0.214 0.338 4560.000     0.811  0.199 0.320 1140.000\n",
       "pos     0.401  0.908 0.556 2640.000     0.399  0.920 0.557  660.000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size=256\n",
    "\n",
    "all_caps = [\"fasttext_crawl\", \"spacy\", \"full_view\", \"key_phrases\", \"nltk\", \"gensim\"] # \"snlp\", \"ibm_max\", \"tmoji\", \"key_phrases\", \"full_view\", \"spacy\", \"nltk\", \"fasttext_crawl\"\n",
    "# all_caps = [\"fasttext_crawl\", ]\n",
    "model_fn = model_builder(LangFeaturesModel, \n",
    "                         dict(classifier_dims=256, num_classes=2, \n",
    "                              gaussian_noise=0.2, dropout=0.1, embedding_dims=256, internal_dims=512,\n",
    "                              capabilities=all_caps, featurizer=\"transformer\", n_layers=2, \n",
    "                              final_layer_builder=fb_1d_loss_builder),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False\n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[1, 4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:53:09.595579Z",
     "start_time": "2020-06-30T17:43:14.052621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e44e8e05454420db38b97c3207f9685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0359d694dc4cd3a155afaf24fdae12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82aad1e430f408fac5ae25aece0f19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=47376696.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Params = 15256576 \n",
      " AlbertClassifer(\n",
      "  (model): AlbertModel(\n",
      "    (embeddings): AlbertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (encoder): AlbertTransformer(\n",
      "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
      "      (albert_layer_groups): ModuleList(\n",
      "        (0): AlbertLayerGroup(\n",
      "          (albert_layers): ModuleList(\n",
      "            (0): AlbertLayer(\n",
      "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (attention): AlbertAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0, inplace=False)\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              )\n",
      "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (pooler_activation): Tanh()\n",
      "  )\n",
      "  (featurizer): TransformerFeaturizer(\n",
      "    (input_nn): Linear(in_features=768, out_features=512, bias=False)\n",
      "    (output_nn): Linear(in_features=512, out_features=256, bias=False)\n",
      "    (transformer): Transformer(\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.0, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.0, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.0, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.0, inplace=False)\n",
      "            (dropout2): Dropout(p=0.0, inplace=False)\n",
      "            (dropout3): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (global_layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (final_layer): MultiTaskForward(\n",
      "    (heads): ModuleList(\n",
      "      (0): CNNHead(\n",
      "        (loss): CrossEntropyLoss()\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.0, inplace=False)\n",
      "          (1): Transpose()\n",
      "          (2): Conv1d(256, 2, kernel_size=(16,), stride=(1,), bias=False)\n",
      "          (3): AdaptiveAvgPool1d(output_size=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6205a409088743c7ae9a830893b7e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df55779e375e486ea228d96c40e7581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  1 Loss = 1.011382 LR = 0.00067442\n",
      "Epoch =  1 Train = 0.588069 Val = 0.602994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323e4000d9e04bef88f5693ea5988d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  2 Loss = 0.780443 LR = 0.00094758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9025db1de2524e2c910d424c95f4224c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  3 Loss = 0.704513 LR = 0.00060697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304bdabd6c924b6197e99facb7490841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  4 Loss = 0.682217 LR = 0.00018654\n",
      "Epoch =  4 Train = 0.649416 Val = 0.660894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df069243741d4354b8455e5cdaca09f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  5 Loss = 0.660487 LR = 0.00000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_or_std</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mean</th>\n",
       "      <th>map</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.661</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">std</th>\n",
       "      <th>map</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train   val\n",
       "mean_or_std metric               \n",
       "mean        map       0.540 0.574\n",
       "            accuracy  0.625 0.623\n",
       "            auc       0.661 0.672\n",
       "std         map       0.000 0.000\n",
       "            accuracy  0.000 0.000\n",
       "            auc       0.000 0.000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">train</th>\n",
       "      <th colspan=\"4\" halign=\"left\">val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>supoort</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>supoort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.688</td>\n",
       "      <td>4560.000</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1140.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.532</td>\n",
       "      <td>2640.000</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.536</td>\n",
       "      <td>660.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train                             val                      \n",
       "    precision recall    f1  supoort precision recall    f1  supoort\n",
       "neg     0.728  0.652 0.688 4560.000     0.731  0.640 0.683 1140.000\n",
       "pos     0.491  0.580 0.532 2640.000     0.489  0.594 0.536  660.000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size=256\n",
    "\n",
    "model_fn = model_builder(AlbertClassifer, \n",
    "                         dict(classifier_dims=256, num_classes=2, embedding_dims=768,\n",
    "                              gaussian_noise=0.6, dropout=0.0, internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder, n_layers=2, \n",
    "                              featurizer=\"transformer\", model='albert-base-v2'),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False\n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[1, 4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T16:18:51.481091Z",
     "start_time": "2020-06-11T16:18:51.478221Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = model_builder(Fasttext1DCNNModel, \n",
    "                         dict(classifer_dims=256, num_classes=2, \n",
    "                              gaussian_noise=0.3, dropout=0.2, embedding_dims=512, internal_dims=256,\n",
    "                             fasttext_file=\"crawl-300d-2M-subword.bin\", classifier=\"transformer\",),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T16:20:18.520223Z",
     "start_time": "2020-06-11T16:18:51.952856Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 1\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, augmentation_weights, scheduler_init_fn=scheduler_init_fn)\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T15:27:03.995069Z",
     "start_time": "2020-06-11T15:27:03.988742Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "822px",
    "left": "0px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
