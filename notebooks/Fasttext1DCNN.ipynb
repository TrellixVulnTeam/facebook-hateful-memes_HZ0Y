{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:24.908816Z",
     "start_time": "2020-07-24T11:40:22.065773Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:24.920845Z",
     "start_time": "2020-07-24T11:40:24.910836Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:24.928876Z",
     "start_time": "2020-07-24T11:40:24.923642Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_speeds = {\"keyboard\": 117, \"char_substitute\": 109, \"char_insert\": 109, \"char_swap\": 114,\n",
    "              \"ocr\": 114, \"char_delete\": 108,\n",
    "              \"word_insert\": 0.0, \"word_substitute\": 0.0, \"text_rotate\": 32,\n",
    "              \"stopword_insert\": 34, \"word_join\": 32, \"word_cutout\": 36,\n",
    "              \"w2v_insert\": 0.0, \"w2v_substitute\": 0.0, \n",
    "              \"fasttext\": 137, \"glove_twitter\": 88, \"glove_wiki\": 82, \"word2vec\": 137,\n",
    "              \"synonym\": 522, \"split\": 110, \"sentence_shuffle\": 67, \"one_third_cut\": 0.0, \"half_cut\":0.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What Augs are useful\n",
    "- What Text models perform best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:25.040526Z",
     "start_time": "2020-07-24T11:40:24.931038Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "choice_probas = {\"keyboard\": 0.1, \"char_substitute\": 0.0, \"char_insert\": 0.1, \"char_swap\": 0.1, \"ocr\": 0.0, \"char_delete\": 0.1,\n",
    "                 \"fasttext\": 0.0, \"glove_twitter\": 0.0, \"glove_wiki\": 0.0, \"word2vec\": 0.0, \"split\": 0.1,\n",
    "                 \"stopword_insert\": 0.3, \"word_join\": 0.1, \"word_cutout\": 0.8,\n",
    "                 \"text_rotate\": 0.5, \"sentence_shuffle\": 0.5, \"one_third_cut\": 0.3, \"half_cut\":0.1}\n",
    "preprocess_text = TextAugment([0.05, 0.05, 0.05, 0.35, 0.3, 0.2], choice_probas, fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=preprocess_text, train_image_transform=None, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = False, dev=False, test_dev=True,\n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=False,)\n",
    "\n",
    "# images = list(data[\"train\"].img) + list(data[\"test\"].img)\n",
    "# pd.DataFrame({\"img\":images}).to_csv(\"image.csv\", header=None, index=None)\n",
    "\n",
    "# ImageAugment([0.2, 0.5, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:25.044781Z",
     "start_time": "2020-07-24T11:40:25.042256Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[\"train\"].label.value_counts()\n",
    "# train = data[\"train\"]\n",
    "\n",
    "# ones = train[train[\"label\"] == 1]\n",
    "# zeros = train[train[\"label\"] == 0].sample(n=len(ones), replace=False)\n",
    "# data[\"train\"] = pd.concat((ones, zeros)).sample(frac=1.0)\n",
    "# data[\"train\"].label.value_counts()\n",
    "\n",
    "# len(set(data[\"train\"][\"id\"])) == data[\"train\"].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:26.317736Z",
     "start_time": "2020-07-24T11:40:26.308132Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-3, weight_decay=1e-7)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:27.535150Z",
     "start_time": "2020-07-24T11:40:27.531304Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs = 10\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([11, 13], gamma=0.25) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T11:44:54.095758Z",
     "start_time": "2020-05-25T11:27:36.177Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Fasttext 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T18:51:29.871327Z",
     "start_time": "2020-07-04T18:39:16.755048Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model_fn = model_builder(Fasttext1DCNNModel,\n",
    "                         dict(\n",
    "                             classifier_dims=256,\n",
    "                             num_classes=2,\n",
    "                             n_layers=2,\n",
    "                             final_layer_builder=fb_1d_loss_builder,\n",
    "                             gaussian_noise=0.15,\n",
    "                             dropout=0.2,\n",
    "                             embedding_dims=256,\n",
    "                             internal_dims=512,\n",
    "                             fasttext_file=\"crawl-300d-2M-subword.bin\",\n",
    "                             featurizer=\"transformer\",\n",
    "                             loss=\"focal\",\n",
    "                             dice_loss_coef=0.0,\n",
    "                             auc_loss_coef=0.0,\n",
    "                         ),\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    model_call_back=reg_sched,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 0.738\t0.734\n",
    "# 0.730\t0.715\n",
    "# 0.730\t0.715\n",
    "# 0.734\t0.731\n",
    "# 0.746\t0.712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Lang Features Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T20:42:41.236616Z",
     "start_time": "2020-07-04T19:14:10.100177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 256\n",
    "# fasttext_crawl 1.9s\n",
    "# spacy 1.8s\n",
    "# full_view 1.4s 0.659\t0.651\n",
    "# gensim 7.5s # 0.718\t0.737\n",
    "# nltk 3s 0.609\t0.585\n",
    "# \"spacy\", \"key_phrases\" 4.2s 0.688\t0.670\n",
    "# \"fasttext_crawl\", \"spacy\", \"key_phrases\", \"gensim\" 20s 0.763\t0.729 2h 49m\n",
    "# \"fasttext_crawl\", \"gensim\" 11s 0.749\t0.733 1h 47m\n",
    "# gensim 8s 0.751\t0.733 1h 20m\n",
    "\n",
    "all_caps = [\n",
    "    \"fasttext_crawl\", \"spacy\", \"full_view\", \"key_phrases\", \"nltk\", \"gensim\"\n",
    "]  # \"snlp\", \"ibm_max\", \"tmoji\", \"key_phrases\", \"full_view\", \"spacy\", \"nltk\", \"fasttext_crawl\"\n",
    "all_caps = [\n",
    "    \"full_view\",\n",
    "]\n",
    "all_caps = [\"fasttext_crawl\", \"spacy\", \"key_phrases\", \"nltk\"]\n",
    "all_caps = [\"fasttext_crawl\", \"gensim\"]\n",
    "model_fn = model_builder(LangFeaturesModel,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              gaussian_noise=0.2,\n",
    "                              dropout=0.2,\n",
    "                              embedding_dims=256,\n",
    "                              internal_dims=512,\n",
    "                              capabilities=all_caps,\n",
    "                              featurizer=\"transformer\",\n",
    "                              loss=\"focal\",\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.0,\n",
    "                              n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder),\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched,\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    validation_epochs=[1, 4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Actibus/Bert_REview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T10:49:53.596455Z",
     "start_time": "2020-07-16T10:35:07.502759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 24\n",
    "batch_size = 256\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"9\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"10\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"11\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              embedding_dims=768,\n",
    "                              gaussian_noise=0.0,\n",
    "                              dropout=0.1,\n",
    "                              word_masking_proba=0.15,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=2,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model=\"activebus/BERT_Review\",\n",
    "                              loss=\"focal\",\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.0,\n",
    "                             ),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched,\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\")\n",
    "r2, p2 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 0.761\t0.749 (0.703\t0.691)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSP Style Finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-20T17:02:59.382066Z",
     "start_time": "2020-07-20T16:39:48.773130Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"2\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "epochs = 24\n",
    "batch_size = 256\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              embedding_dims=768,\n",
    "                              gaussian_noise=0.75,\n",
    "                              dropout=0.1,\n",
    "                              word_masking_proba=0.15,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=3,\n",
    "                              n_decoders=3,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./distilbert-nsp',\n",
    "                              loss=\"focal\",\n",
    "                              classification_head=\"decoder_ensemble\",\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.0, # fasttext_vector_config=dict(n_decoders=2, gru_layers=2)\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched,\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\")\n",
    "r2, p2 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# Try with_replacement\n",
    "# 0.810\t0.661 (0.724\t0.600) (gaussian_noise=0.75, dropout=0.1, word_masking_proba=0.2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:40:43.717697Z",
     "start_time": "2020-07-24T11:40:32.679971Z"
    }
   },
   "outputs": [],
   "source": [
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"2\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "epochs = 24\n",
    "batch_size = 256\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              gaussian_noise=0.2,\n",
    "                              dropout=0.2,\n",
    "                              word_masking_proba=0.25,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=2,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./distilbert-nsp',\n",
    "                              loss=\"focal\",\n",
    "                              classification_head=\"decoder_ensemble\", # head_ensemble\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.5,\n",
    "                              attention_drop_proba=0.2,\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched, # reg_sched\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\")\n",
    "r2, p2 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# auc_loss_coef=0.5\n",
    "# 0.853 0.661 (0.757 0.596) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.852\t0.658 (0.748\t0.604) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.2,\n",
    "# 0.857\t0.661 (0.761\t0.590) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.845\t0.657 (0.757\t0.592) gaussian_noise=0.1, dropout=0.25, word_masking_proba=0.25,\n",
    "# 0.841\t0.644 (0.753\t0.578) gaussian_noise=0.1, dropout=0.25, word_masking_proba=0.2,\n",
    "# 0.861\t0.647 (0.759\t0.594) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.857\t0.652 (0.756\t0.576) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.848\t0.661 (0.751\t0.592) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.853\t0.657 (0.755\t0.588) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.853\t0.661 (0.750\t0.602) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.852\t0.649 (0.757\t0.578) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "\n",
    "# No reg_sched testing\n",
    "# 0.848\t0.652 (0.754\t0.590) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "\n",
    "# Cnn1D head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T05:22:23.882895Z",
     "start_time": "2020-07-24T05:04:41.661316Z"
    }
   },
   "outputs": [],
   "source": [
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"2\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "epochs = 24\n",
    "batch_size = 256\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              gaussian_noise=0.1,\n",
    "                              dropout=0.25,\n",
    "                              word_masking_proba=0.25,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=2,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='distilbert-cor',\n",
    "                              loss=\"focal\",\n",
    "                              classification_head=\"decoder_ensemble\", # decoder_ensemble\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.5,\n",
    "                              attention_drop_proba=0.2,\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched, # reg_sched\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\")\n",
    "r3, p3 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# auc_loss_coef=0.5\n",
    "# 0.853 0.661 (0.757 0.596) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.852\t0.658 (0.748\t0.604) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.2,\n",
    "# 0.857\t0.661 (0.761\t0.590) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.845\t0.657 (0.757\t0.592) gaussian_noise=0.1, dropout=0.25, word_masking_proba=0.25,\n",
    "# 0.841\t0.644 (0.753\t0.578) gaussian_noise=0.1, dropout=0.25, word_masking_proba=0.2,\n",
    "# 0.861\t0.647 (0.759\t0.594) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.857\t0.652 (0.756\t0.576) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.848\t0.661 (0.751\t0.592) gaussian_noise=0.1, dropout=0.15, word_masking_proba=0.15,\n",
    "# 0.853\t0.657 (0.755\t0.588) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.853\t0.661 (0.750\t0.602) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "# 0.852\t0.649 (0.757\t0.578) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "\n",
    "# No reg_sched testing\n",
    "# 0.848\t0.652 (0.754\t0.590) gaussian_noise=0.1, dropout=0.2, word_masking_proba=0.2,\n",
    "\n",
    "# Cnn1D head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETR Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T09:21:10.661661Z",
     "start_time": "2020-07-24T09:21:10.657376Z"
    }
   },
   "outputs": [],
   "source": [
    "from facebook_hateful_memes_detector.utils import in_notebook, CNNHead, MultiLayerTransformerDecoderHead, AveragedLinearHead, OneTokenPositionLinearHead, MultiTaskForward, CNN2DHead\n",
    "def fb_detr_loss_builder(n_dims, n_tokens, n_out, dropout, **kwargs):\n",
    "    loss = kwargs.pop(\"loss\", \"classification\")\n",
    "    cnn = MultiLayerTransformerDecoderHead(n_dims, n_tokens, n_out, dropout=0.4, \n",
    "                                           gaussian_noise=0.75, n_layers=3, loss=loss)\n",
    "    return cnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T09:42:56.341490Z",
     "start_time": "2020-07-24T09:21:11.043305Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 24\n",
    "batch_size = 256\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=5e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              gaussian_noise=0.15,\n",
    "                              dropout=0.25,\n",
    "                              word_masking_proba=0.25,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_detr_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=0,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=96,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./distilbert-nsp',\n",
    "                              classification_head=\"decoder_ensemble\",\n",
    "                              loss=\"focal\",\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.5,\n",
    "                              attention_drop_proba=0.2,\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    model_call_back=reg_sched,\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\")\n",
    "r2, p2 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 0.824\t0.649 (0.748\t0.576) (gaussian_noise=0.75, dropout=0.25, word_masking_proba=0.25,)\n",
    "# 0.829\t0.654 (0.744\t0.584) (gaussian_noise=0.5, dropout=0.25, word_masking_proba=0.25,)\n",
    "# 0.811\t0.635 (0.740\t0.578) (gaussian_noise=0.5, dropout=0.25, word_masking_proba=0.25,)\n",
    "# 0.834\t0.630 (0.755\t0.566) (gaussian_noise=0.5, dropout=0.2, word_masking_proba=0.25,)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Normal Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T18:25:47.199884Z",
     "start_time": "2020-07-21T18:25:47.191403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"2\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e3,\n",
    "                    \"finetune\": False\n",
    "                },\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e1,\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"],\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "epochs = 24\n",
    "batch_size = 256\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              gaussian_noise=0.1,\n",
    "                              dropout=0.2,\n",
    "                              word_masking_proba=0.2,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=3,\n",
    "                              n_decoders=3,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=32,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./distilbert-nsp',\n",
    "                              loss=\"focal\",\n",
    "                              classification_head=\"decoder_ensemble\", # decoder_ensemble\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.5,\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-21T18:35:26.531494Z",
     "start_time": "2020-07-21T18:25:56.486297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, \n",
    "                                           scheduler_init_fn=scheduler_init_fn, \n",
    "                                           model_call_back=reg_sched,\n",
    "                                           sampling_policy=\"without_replacement\",\n",
    "                                           validation_epochs=[15, 31, 34, 42],\n",
    "                                          )\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## DETR Style head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T18:36:42.888565Z",
     "start_time": "2020-07-18T18:22:55.511030Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 1000,\n",
    "        \"finetune\": False,\n",
    "        \"encoder\": {\n",
    "            \"layer\": {\n",
    "                \"3\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e2,\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"lr\": optimizer_params[\"lr\"] / 1e1,\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "model_fn = model_builder(AlbertClassifer,\n",
    "                         dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              embedding_dims=768,\n",
    "                              gaussian_noise=0.75,\n",
    "                              dropout=0.25,\n",
    "                              word_masking_proba=0.25,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_detr_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=0,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./distilbert-nsp',\n",
    "                              loss=\"focal\",\n",
    "                              dice_loss_coef=0.0,\n",
    "                              auc_loss_coef=0.0,\n",
    "                              finetune=False),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "epochs = 24\n",
    "batch_size = 256\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs,\n",
    "                                           scheduler_init_fn=scheduler_init_fn, \n",
    "                                           model_call_back=reg_sched, validation_epochs=[2, 5, 7],\n",
    "                                           sampling_policy=\"without_replacement\")\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(10)\n",
    "\n",
    "# 0.6723\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# What train-auc does we achieve if all examples have same score.\n",
    "# What train-auc does we achieve if all examples have random score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T07:17:50.760560Z",
     "start_time": "2020-07-15T07:17:50.752333Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "822px",
    "left": "0px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
