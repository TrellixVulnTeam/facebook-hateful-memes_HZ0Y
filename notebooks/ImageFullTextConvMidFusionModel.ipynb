{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.541608Z",
     "start_time": "2020-06-19T10:15:58.995038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, ImageFullTextConvMidFusionModel, MultiImageMultiTextAttentionEarlyFusionModel\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.549345Z",
     "start_time": "2020-06-19T10:16:08.544189Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.676250Z",
     "start_time": "2020-06-19T10:16:08.550828Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = get_image2torchvision_transforms()\n",
    "aug_speeds = {\"keyboard\": 117, \"char_substitute\": 109, \"char_insert\": 109, \"char_swap\": 114,\n",
    "              \"ocr\": 114, \"char_delete\": 108,\n",
    "              \"word_insert\": 0.0, \"word_substitute\": 0.0, \"text_rotate\": 32,\n",
    "              \"stopword_insert\": 34, \"word_join\": 32, \"word_cutout\": 36,\n",
    "              \"w2v_insert\": 0.0, \"w2v_substitute\": 0.0, \n",
    "              \"fasttext\": 137, \"glove_twitter\": 88, \"glove_wiki\": 82, \"word2vec\": 137,\n",
    "              \"synonym\": 522, \"split\": 110, \"sentence_shuffle\": 67, \"one_third_cut\": 0.0, \"half_cut\":0.0}\n",
    "\n",
    "choice_probas = {\"keyboard\": 0.1, \"char_substitute\": 0.0, \"char_insert\": 0.1, \"char_swap\": 0.1, \"ocr\": 0.0, \"char_delete\": 0.1,\n",
    "                 \"fasttext\": 0.0, \"glove_twitter\": 0.0, \"glove_wiki\": 0.0, \"word2vec\": 0.0, \"split\": 0.1,\n",
    "                 \"stopword_insert\": 0.3, \"word_join\": 0.1, \"word_cutout\": 0.8,\n",
    "                 \"text_rotate\": 0.5, \"sentence_shuffle\": 0.5, \"one_third_cut\": 0.3, \"half_cut\":0.1,\n",
    "                 \"synonym\": 0.0,}\n",
    "preprocess_text = TextAugment([0.05, 0.05, 0.05, 0.35, 0.3, 0.2], choice_probas, fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.773402Z",
     "start_time": "2020-06-19T10:16:08.678626Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=preprocess_text, train_image_transform=None, \n",
    "                 test_text_transform=None, test_image_transform=None, \n",
    "                 cache_images = True, use_images = True, dev=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.782811Z",
     "start_time": "2020-06-19T10:16:08.775624Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.788282Z",
     "start_time": "2020-06-19T10:16:08.783890Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs = 3\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([5, 7, 10, 17], gamma=0.1) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "augmentation_weights = {\"None\": 1.0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:16:08.793377Z",
     "start_time": "2020-06-19T10:16:08.789390Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[\"caption_features\"], num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.2, dropout=0.1, \n",
    "                                                                                    embedding_dims=128, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=16)],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.1, ),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-19T10:15:58.915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params = 5111552 \n",
      " MultiImageMultiTextAttentionEarlyFusionModel(\n",
      "  (im_models): ModuleDict(\n",
      "    (caption_features): LambdaLayer()\n",
      "  )\n",
      "  (im_procs): ModuleDict(\n",
      "    (caption_features): Identity()\n",
      "  )\n",
      "  (tx_models): ModuleDict(\n",
      "    (tx_0): Fasttext1DCNNModel(\n",
      "      (crawl_nn): ExpandContract(\n",
      "        (nn): Sequential(\n",
      "          (0): Transpose()\n",
      "          (1): Dropout(p=0.1, inplace=False)\n",
      "          (2): Conv1d(600, 256, kernel_size=(1,), stride=(1,), groups=8, bias=False)\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "          (4): Dropout(p=0.1, inplace=False)\n",
      "          (5): Conv1d(256, 128, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "          (6): Transpose()\n",
      "          (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (featurizer): CNN1DFeaturizer(\n",
      "        (featurizer): Sequential(\n",
      "          (0): Dropout(p=0.1, inplace=False)\n",
      "          (1): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=4, bias=False)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "          (3): GaussianNoise()\n",
      "          (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "          (5): Dropout(p=0.1, inplace=False)\n",
      "          (6): LeakyReLU(negative_slope=0.01)\n",
      "          (7): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (8): GaussianNoise()\n",
      "          (9): Residual1DConv(\n",
      "            (r1): Sequential(\n",
      "              (0): Dropout(p=0.1, inplace=False)\n",
      "              (1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): GaussianNoise()\n",
      "            )\n",
      "            (r2): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "            (channel_sizer): Sequential(\n",
      "              (0): Dropout(p=0.1, inplace=False)\n",
      "              (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            )\n",
      "            (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (10): Residual1DConv(\n",
      "            (r1): Sequential(\n",
      "              (0): Dropout(p=0.1, inplace=False)\n",
      "              (1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): GaussianNoise()\n",
      "            )\n",
      "            (r2): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "            (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (11): Residual1DConv(\n",
      "            (r1): Sequential(\n",
      "              (0): Dropout(p=0.1, inplace=False)\n",
      "              (1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "              (2): LeakyReLU(negative_slope=0.01)\n",
      "              (3): GaussianNoise()\n",
      "            )\n",
      "            (r2): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=4, bias=False)\n",
      "            (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (featurizer): TransformerEnsembleFeaturizer(\n",
      "    (ensemble_inp): ModuleDict(\n",
      "      (caption_features): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (tx_0): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norms): ModuleDict(\n",
      "      (caption_features): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (tx_0): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (em): Embedding(2, 256)\n",
      "    (output_nn): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "      (3): GaussianNoise()\n",
      "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pos_encoder2d): PositionalEncoding2D(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_layer): MultiTaskForward(\n",
      "    (heads): ModuleList(\n",
      "      (0): CNNHead(\n",
      "        (loss): CrossEntropyLoss()\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.1, inplace=False)\n",
      "          (1): Transpose()\n",
      "          (2): Conv1d(256, 2, kernel_size=(16,), stride=(1,), bias=False)\n",
      "          (3): AdaptiveAvgPool1d(output_size=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1de89ed24cf45d690667f9cd295e707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8403accc054564a273968f6113fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=113.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 19])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "\n",
    "# 0.747\t0.727\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.185454Z",
     "start_time": "2020-06-18T08:58:40.580Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[\"torchvision_resnet18\"], num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.1, dropout=0.05, \n",
    "                                                                                    embedding_dims=128, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=16)],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.1, dropout=0.05, ),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.186006Z",
     "start_time": "2020-06-18T08:58:40.582Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fn = model_builder(ImageFullTextConvMidFusionModel, \n",
    "                         dict(image_model=\"torchvision_resnet18\",num_classes=2, \n",
    "                              text_model_class=Fasttext1DCNNModel, internal_dims=256, classifier_dims=256,\n",
    "                              text_model_params=dict(classifier_dims=256, num_classes=2, n_tokens_out=8,\n",
    "                                                     n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                     gaussian_noise=0.3, dropout=0.2, \n",
    "                                                     embedding_dims=128, internal_dims=256, featurizer=\"cnn\",),\n",
    "                              text_in_channels=256, final_layer_builder=fb_2d_loss_builder,\n",
    "                              gaussian_noise=0.1, dropout=0.1, ),\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.186511Z",
     "start_time": "2020-06-18T08:58:40.593Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "n_tests = 1\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs,augmentation_weights, multi_eval=multi_eval, kfold=kfold, scheduler_init_fn=scheduler_init_fn)\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 21m 41s 7528192 0.807\t0.700\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187026Z",
     "start_time": "2020-06-18T08:58:40.596Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 1\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, augmentation_weights, scheduler_init_fn=scheduler_init_fn)\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187634Z",
     "start_time": "2020-06-18T08:58:40.600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
