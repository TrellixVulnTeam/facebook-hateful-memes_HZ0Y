{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:43:02.582796Z",
     "start_time": "2020-10-11T12:42:59.556729Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "DIR = os.getcwd()\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, DefinedAffine, DefinedColorJitter, DefinedRandomPerspective, ImageAugment\n",
    "from PIL import Image\n",
    "from facebook_hateful_memes_detector.utils import get_image_info_fn, set_device, get_device\n",
    "from torchvision import transforms\n",
    "import joblib\n",
    "from tqdm.auto import tqdm, trange\n",
    "from joblib import Parallel, delayed\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment, get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.models.external.detr import get_detr_model\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "\n",
    "def hash(x):\n",
    "    return joblib.hashing.hash(x, 'sha1')\n",
    "\n",
    "def print_code(func):\n",
    "    import inspect\n",
    "    from pygments import highlight\n",
    "    from pygments.lexers import PythonLexer\n",
    "    from pygments.formatters import TerminalFormatter\n",
    "\n",
    "    code = \"\".join(inspect.getsourcelines(func)[0])\n",
    "    print(highlight(code, PythonLexer(), TerminalFormatter()))\n",
    "\n",
    "set_device('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:07:06.195294Z",
     "start_time": "2020-10-10T07:07:05.791667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-10 07:07:05--  https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/images/input.jpg\n",
      "Resolving raw.githubusercontent.com... 151.101.52.133\n",
      "Connecting to raw.githubusercontent.com|151.101.52.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 209222 (204K) [image/jpeg]\n",
      "Saving to: “input.jpg.1”\n",
      "\n",
      "100%[======================================>] 209,222     --.-K/s   in 0.03s   \n",
      "\n",
      "2020-10-10 07:07:06 (6.31 MB/s) - “input.jpg.1” saved [209222/209222]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/images/input.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:43:09.274539Z",
     "start_time": "2020-10-11T12:43:09.172530Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_datasets(data_dir=\"../data/\",\n",
    "                    train_text_transform=None,\n",
    "                    train_image_transform=None,\n",
    "                    test_text_transform=None,\n",
    "                    test_image_transform=None,\n",
    "                    train_torchvision_pre_image_transform=None,\n",
    "                    test_torchvision_pre_image_transform=None,\n",
    "                    cache_images=False,\n",
    "                    use_images=True,\n",
    "                    dev=False,\n",
    "                    test_dev=True,\n",
    "                    keep_original_text=True,\n",
    "                    keep_original_image=True,\n",
    "                    keep_processed_image=True,\n",
    "                    keep_torchvision_image=False,\n",
    "                    train_mixup_config=None)\n",
    "\n",
    "data[\"test\"][\"label\"] = -1\n",
    "\n",
    "df = pd.concat((data[\"train\"],\n",
    "                data[\"dev\"], \n",
    "                data[\"test\"]))\n",
    "\n",
    "dataset = convert_dataframe_to_dataset(df, data[\"metadata\"], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:28:42.720879Z",
     "start_time": "2020-10-11T12:28:26.348628Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for transformation in list(get_transforms_for_bbox_methods().transforms + get_transforms_for_multiview()):\n",
    "    display(transformation(dataset[0]['original_image']))\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-11T12:43:32.433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bcd13ff9b14745a7ec639b6dc69528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtractor : Loaded Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ahemf/mygit/vqa-maskrcnn-benchmark/maskrcnn_benchmark/structures/boxlist_ops.py:45: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:773.)\n",
      "  keep = ((ws >= min_size) & (hs >= min_size)).nonzero().squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
      "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
      "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
      "\n",
      "LXMERTFeatureExtractor : Loaded Model...\n"
     ]
    }
   ],
   "source": [
    "from facebook_hateful_memes_detector.utils import get_image_info_fn\n",
    "from facebook_hateful_memes_detector.preprocessing import get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.preprocessing import get_transforms_for_multiview\n",
    "all_transforms = list(get_transforms_for_bbox_methods().transforms + get_transforms_for_multiview())\n",
    "get_img_details = get_image_info_fn(enable_encoder_feats=False, device=get_device())[\"get_img_details\"]\n",
    "get_lxmert_details = get_image_info_fn(enable_encoder_feats=False, device=get_device())[\"get_lxmert_details\"]\n",
    "\n",
    "def lxmert_faster_rcnn_fn(img):\n",
    "    _ = get_img_details(img)\n",
    "    _ = get_lxmert_details(img)\n",
    "\n",
    "for elem in tqdm(iter(dataset), total=len(dataset)):\n",
    "    image = elem[\"original_image\"]\n",
    "    for idx, transformation in enumerate(all_transforms):\n",
    "        lxmert_faster_rcnn_fn(transformation(image.copy()))\n",
    "        if idx == 0:\n",
    "            for _ in range(2):\n",
    "                lxmert_faster_rcnn_fn(transformation(image.copy()))\n",
    "        if idx == 2:\n",
    "            for _ in range(8):\n",
    "                lxmert_faster_rcnn_fn(transformation(image.copy()))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_stats = get_global(\"cache_stats\")\n",
    "cache_stats['get_img_details']\n",
    "cache_stats['get_lxmert_details']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:03:13.282783Z",
     "start_time": "2020-10-11T12:03:10.870875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b8961b27ef420eb5a5bbaf45135f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"input.jpg\")\n",
    "im_transform = get_transforms_for_bbox_methods()\n",
    "from facebook_hateful_memes_detector.preprocessing import HalfSwap, QuadrantCut, DefinedRotation, DefinedAffine\n",
    "# im_transform = transforms.RandomAffine(0, scale=(1.25, 1.25))\n",
    "hashes = Parallel(n_jobs=8, backend='threading')(delayed(lambda i: hash(im_transform(i)))(img.copy()) for i in trange(1000))\n",
    "hashes = set(hashes)\n",
    "len(hashes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:55:27.922836Z",
     "start_time": "2020-10-11T11:55:27.919481Z"
    }
   },
   "outputs": [],
   "source": [
    "im = Image.open(\"input.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T11:55:37.734277Z",
     "start_time": "2020-10-11T11:55:29.364624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 ms ± 27.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit im_transform(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-12T19:31:22.782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1559570253754fab818c5d1f48f6e5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureExtractor : Loaded Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ahemf/mygit/vqa-maskrcnn-benchmark/maskrcnn_benchmark/structures/boxlist_ops.py:45: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keep = ((ws >= min_size) & (hs >= min_size)).nonzero().squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCaptionFeatures : Loaded Model...\n",
      "LXMERTFeatureExtractor : Loaded Model...\n",
      "DETR detr_resnet50 : Loaded Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ahemf/.cache/torch/hub/facebookresearch_detr_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR detr_resnet50_panoptic : Loaded Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ahemf/.cache/torch/hub/facebookresearch_detr_master\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fns = get_image_info_fn(enable_encoder_feats=True, enable_image_captions=False)\n",
    "cache_fns = [fns[\"get_img_details\"], fns[\"get_encoder_feats\"], \n",
    "             fns[\"get_lxmert_details\"], \n",
    "             get_detr_model(get_device(), \"detr_resnet50\")[\"detr_fn\"], \n",
    "             get_detr_model(get_device(), \"detr_resnet50_panoptic\")[\"detr_fn\"], lambda x: x]\n",
    "\n",
    "images = list(data[\"train\"].img.values) + list(data[\"test\"].img.values)\n",
    "try:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    scaler = GradScaler()\n",
    "    use_autocast = \"cuda\" in str(get_device())\n",
    "except:\n",
    "    pass\n",
    "for i in tqdm(images):\n",
    "    img = Image.open(i)\n",
    "    for k, aug in augs_dict.items():\n",
    "        for _ in range(16):\n",
    "            img_copy = aug(img.copy())\n",
    "            for fn in cache_fns:\n",
    "                with autocast():\n",
    "                    _ = fn(img_copy)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# We need Qcut for robustness\n",
    "# We need DefinedAffine translate since in this problem we care about presence of object not position\n",
    "# We need Image models trained on classification which only care about presence not position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T08:32:19.276925Z",
     "start_time": "2020-07-11T08:32:16.252218Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "texts = pd.read_csv(\"text.csv\", header=None)[0].values\n",
    "\n",
    "m = lambda x: tokenizer.encode_plus(x, add_special_tokens=True, pad_to_max_length=False, truncation=False)\n",
    "tlens = [len(d['input_ids']) for d in map(m, texts)]\n",
    "\n",
    "np.percentile(tlens, [97, 99, 99.5, 99.9, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import get_image_info_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T18:48:53.053410Z",
     "start_time": "2020-06-22T18:48:52.971861Z"
    }
   },
   "outputs": [],
   "source": [
    "torchvision.transforms.RandomPerspective(p=1.0)(Image.open(\"input.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T08:30:34.002850Z",
     "start_time": "2020-07-23T08:30:33.780236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    }
   ],
   "source": [
    "fns = get_image_info_fn(enable_encoder_feats=True, enable_image_captions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T09:20:42.500399Z",
     "start_time": "2020-07-26T09:20:34.811763Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
      "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
      "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
      "\n",
      "LXMERTFeatureExtractor : Loaded Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahemf/anaconda3/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:773.)\n",
      "  filter_inds = filter_mask.nonzero()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4331, device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5820, device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Boxes(tensor([[169.3243, 214.3307, 485.1099, 469.7549],\n",
       "        [100.7880, 251.3626, 394.6440, 480.0000],\n",
       "        [586.3296,   0.0000, 638.9190, 353.0089],\n",
       "        [608.1302,  61.5700, 637.4992, 423.6490],\n",
       "        [281.5395, 162.0848, 328.3549, 194.3590],\n",
       "        [157.3794,  92.9709, 392.1783, 461.2858],\n",
       "        [222.4158, 291.6465, 566.1779, 480.0000],\n",
       "        [ 41.3324, 181.5984, 349.9705, 450.4261],\n",
       "        [ 13.8716,   1.7292, 207.8326, 437.1108],\n",
       "        [381.5179, 310.5241, 618.9825, 417.9209],\n",
       "        [261.5557, 192.7572, 362.9944, 429.1843],\n",
       "        [203.8108,   0.0000, 300.6809, 279.9798],\n",
       "        [420.2803, 278.9125, 637.1599, 389.4050],\n",
       "        [  2.9243,   0.0000, 123.0734, 353.0846],\n",
       "        [ 55.2990,  27.5763, 128.4013, 386.0382],\n",
       "        [246.5886, 159.6546, 347.5096, 360.4674],\n",
       "        [ 44.2803, 321.1058, 584.3936, 477.0761],\n",
       "        [171.0541, 371.0668, 462.8420, 469.1741],\n",
       "        [101.0942, 165.9819, 550.5664, 416.4953],\n",
       "        [  1.5654,   0.0000, 529.4667, 280.5789],\n",
       "        [159.0476,   1.3941, 354.3626, 316.8224],\n",
       "        [555.9099, 269.8074, 602.9631, 373.0794],\n",
       "        [407.5941,   0.6596, 635.0023, 326.4306],\n",
       "        [110.2611,   0.0000, 617.4709, 239.9266],\n",
       "        [123.0698, 417.4258, 620.6061, 479.7397],\n",
       "        [  0.0000, 363.9565, 399.8160, 478.1070],\n",
       "        [114.0947, 339.6641, 640.0000, 478.0359],\n",
       "        [219.6497,   6.5819, 640.0000, 286.9289],\n",
       "        [278.4822, 206.5085, 339.9811, 313.6124],\n",
       "        [  0.0000,   0.0000, 447.7210, 168.0107],\n",
       "        [499.1521, 273.2001, 569.3058, 363.1602],\n",
       "        [339.4074,  75.1475, 634.9698, 410.3748],\n",
       "        [555.5646, 269.8882, 602.8911, 373.4716],\n",
       "        [  0.0000,   0.0000, 292.7031, 259.5059],\n",
       "        [ 78.2532, 123.9411, 589.1075, 365.9051],\n",
       "        [  5.5231, 272.3394,  91.5774, 461.9183]], device='cuda:0'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9688, 0.9398, 0.7171, 0.7034, 0.6957, 0.6017, 0.5914, 0.5399, 0.5305,\n",
       "        0.5088, 0.4935, 0.4671, 0.4599, 0.4557, 0.4474, 0.4470, 0.4280, 0.3849,\n",
       "        0.3726, 0.3425, 0.3416, 0.3362, 0.3179, 0.3128, 0.3056, 0.2993, 0.2967,\n",
       "        0.2910, 0.2739, 0.2670, 0.2654, 0.2511, 0.2486, 0.2417, 0.2259, 0.2201],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from facebook_hateful_memes_detector.utils.detectron_v1_object_detector import LXMERTFeatureExtractor, persistent_caching_fn\n",
    "lxmert_feature_extractor = LXMERTFeatureExtractor(get_device(), do_autocast=False)\n",
    "def fn(x):\n",
    "    return x\n",
    "fn = persistent_caching_fn(fn, \"random_2323\", False)\n",
    "fn(2)\n",
    "img = Image.open(\"input.jpg\")\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "feats = lxmert_feature_extractor(img)  \n",
    "\n",
    "feats[0].scores.mean()\n",
    "feats[1].mean()\n",
    "feats[0].pred_boxes\n",
    "feats[0].scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T10:43:08.075599Z",
     "start_time": "2020-07-23T10:43:07.962756Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4330, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5820, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Boxes(tensor([[1.6930e+02, 2.1420e+02, 4.8495e+02, 4.6980e+02],\n",
       "        [1.0069e+02, 2.5155e+02, 3.9438e+02, 4.8000e+02],\n",
       "        [5.8632e+02, 0.0000e+00, 6.3880e+02, 3.5310e+02],\n",
       "        [6.0791e+02, 6.1763e+01, 6.3700e+02, 4.2360e+02],\n",
       "        [2.8146e+02, 1.6200e+02, 3.2840e+02, 1.9440e+02],\n",
       "        [1.5730e+02, 9.3000e+01, 3.9198e+02, 4.6140e+02],\n",
       "        [2.2253e+02, 2.9175e+02, 5.6622e+02, 4.8000e+02],\n",
       "        [4.1425e+01, 1.8150e+02, 3.5029e+02, 4.5030e+02],\n",
       "        [1.3899e+01, 1.6840e+00, 2.0769e+02, 4.3710e+02],\n",
       "        [3.7998e+02, 3.1110e+02, 6.2021e+02, 4.1670e+02],\n",
       "        [2.6152e+02, 1.9245e+02, 3.6289e+02, 4.2900e+02],\n",
       "        [2.0379e+02, 0.0000e+00, 3.0066e+02, 2.7990e+02],\n",
       "        [4.2017e+02, 2.7855e+02, 6.3700e+02, 3.8910e+02],\n",
       "        [2.9381e+00, 0.0000e+00, 1.2311e+02, 3.5310e+02],\n",
       "        [5.5258e+01, 2.7713e+01, 1.2843e+02, 3.8610e+02],\n",
       "        [2.4652e+02, 1.5975e+02, 3.4759e+02, 3.6060e+02],\n",
       "        [4.4124e+01, 3.2100e+02, 5.8452e+02, 4.7700e+02],\n",
       "        [1.7110e+02, 3.7080e+02, 4.6306e+02, 4.6920e+02],\n",
       "        [1.0114e+02, 1.6590e+02, 5.5093e+02, 4.1640e+02],\n",
       "        [1.5030e+00, 0.0000e+00, 5.2933e+02, 2.8050e+02],\n",
       "        [1.5910e+02, 1.4684e+00, 3.5449e+02, 3.1680e+02],\n",
       "        [5.5573e+02, 2.6970e+02, 6.0311e+02, 3.7290e+02],\n",
       "        [4.0787e+02, 6.0879e-01, 6.3520e+02, 3.2640e+02],\n",
       "        [1.1014e+02, 0.0000e+00, 6.1721e+02, 2.3985e+02],\n",
       "        [1.2311e+02, 4.1730e+02, 6.2081e+02, 4.7970e+02],\n",
       "        [0.0000e+00, 3.6420e+02, 3.9978e+02, 4.7820e+02],\n",
       "        [1.1404e+02, 3.3930e+02, 6.4000e+02, 4.7790e+02],\n",
       "        [2.1953e+02, 6.6656e+00, 6.4000e+02, 2.8665e+02],\n",
       "        [2.7846e+02, 2.0670e+02, 3.4009e+02, 3.1380e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 4.4776e+02, 1.6800e+02],\n",
       "        [4.9934e+02, 2.7300e+02, 5.6952e+02, 3.6300e+02],\n",
       "        [3.3919e+02, 7.5113e+01, 6.3460e+02, 4.1010e+02],\n",
       "        [5.5543e+02, 2.6985e+02, 6.0281e+02, 3.7350e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 2.9271e+02, 2.5950e+02],\n",
       "        [7.8425e+01, 1.2398e+02, 5.8932e+02, 3.6600e+02],\n",
       "        [5.5108e+00, 2.7225e+02, 9.1696e+01, 4.6200e+02]], device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.9688, 0.9399, 0.7174, 0.7038, 0.6960, 0.6010, 0.5914, 0.5405, 0.5300,\n",
       "        0.4952, 0.4940, 0.4683, 0.4603, 0.4561, 0.4477, 0.4462, 0.4271, 0.3841,\n",
       "        0.3730, 0.3433, 0.3431, 0.3367, 0.3188, 0.3125, 0.3050, 0.2994, 0.2975,\n",
       "        0.2961, 0.2740, 0.2673, 0.2652, 0.2508, 0.2483, 0.2417, 0.2267, 0.2204],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from facebook_hateful_memes_detector.utils.detectron_v1_object_detector import LXMERTFeatureExtractor\n",
    "lxmert_feature_extractor = LXMERTFeatureExtractor(get_device())\n",
    "img = Image.open(\"input.jpg\")\n",
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    feats = lxmert_feature_extractor(img)  \n",
    "len(feats)\n",
    "feats[0].scores.mean()\n",
    "feats[1].mean()\n",
    "feats[0].pred_boxes\n",
    "feats[0].scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T11:56:48.616651Z",
     "start_time": "2020-06-23T11:56:41.485207Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res, info = fns[\"feature_extractor\"](Image.open(\"../data/img/08291.png\"))\n",
    "res[:2, :8]\n",
    "info[\"boxes\"][:4]\n",
    "info[\"objects\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T11:56:34.048809Z",
     "start_time": "2020-06-23T11:56:34.003492Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res, info = fns[\"get_img_details\"](Image.open(\"../data/img/08291.png\"))\n",
    "res[:2, :8]\n",
    "info[\"boxes\"][:4]\n",
    "info[\"objects\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T11:58:59.505064Z",
     "start_time": "2020-06-23T11:58:57.659942Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fns[\"get_image_captions\"](\"../data/img/08291.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:27:05.795956Z",
     "start_time": "2020-06-23T08:27:05.714646Z"
    }
   },
   "outputs": [],
   "source": [
    "im = im_transform(Image.open(\"input.jpg\"))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:27:11.730520Z",
     "start_time": "2020-06-23T08:27:11.561639Z"
    }
   },
   "outputs": [],
   "source": [
    "instances, roi_features = fns[\"get_lxmert_details\"](im)\n",
    "instances.pred_boxes.tensor # boxes\n",
    "roi_features # feats\n",
    "# (feats, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:32:07.896872Z",
     "start_time": "2020-06-23T08:32:07.885094Z"
    }
   },
   "outputs": [],
   "source": [
    "fns[\"get_encoder_feats\"](\"../data/img/08291.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
