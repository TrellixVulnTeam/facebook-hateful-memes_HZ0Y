{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T18:32:23.612131Z",
     "start_time": "2020-07-14T18:32:20.738527Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T18:32:28.993082Z",
     "start_time": "2020-07-14T18:32:28.878605Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "\n",
    "choice_probas = {\"keyboard\": 0.1, \"char_substitute\": 0.0, \"char_insert\": 0.1, \"char_swap\": 0.0, \"ocr\": 0.0, \"char_delete\": 0.1,\n",
    "                 \"fasttext\": 0.0, \"glove_twitter\": 0.0, \"glove_wiki\": 0.0, \"word2vec\": 0.0, \"split\": 0.1,\n",
    "                 \"stopword_insert\": 0.3, \"word_join\": 0.1, \"word_cutout\": 0.8,\n",
    "                 \"text_rotate\": 0.5, \"sentence_shuffle\": 0.5, \"one_third_cut\": 0.4, \"half_cut\":0.1}\n",
    "preprocess_text = TextAugment([0.0, 0.1, 0.05, 0.35, 0.3, 0.2], choice_probas, fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "\n",
    "augs_dict = dict(\n",
    "    grayscale=transforms.Grayscale(num_output_channels=3),\n",
    "    hflip=transforms.RandomHorizontalFlip(p=1.0),\n",
    "    rc2=transforms.Compose(\n",
    "        [transforms.Resize(480),\n",
    "         transforms.CenterCrop(400)]),\n",
    "    rotate=DefinedRotation(15),\n",
    "    affine=DefinedAffine(0, scale=(0.6, 0.6)),\n",
    "    translate1=DefinedAffine(0, translate=(0.25, 0.25)),\n",
    ")\n",
    "im_transform = ImageAugment(count_proba=[0.0, 1.0], augs_dict=augs_dict, choice_probas=\"uniform\")\n",
    "\n",
    "\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=preprocess_text, train_image_transform=im_transform, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = True, dev=False, \n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=True,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T18:32:33.050846Z",
     "start_time": "2020-07-14T18:32:33.041268Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T18:32:33.785777Z",
     "start_time": "2020-07-14T18:32:33.779696Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs = 25\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([5, 7, 10, 17], gamma=0.1) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "augmentation_weights = {\"None\": 1.0}\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "\n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/750},\n",
    "                                                      \"8\": {\"lr\": optimizer_params[\"lr\"]/250},\n",
    "                                                      \"lr\": optimizer_params[\"lr\"]/2000},\n",
    "                             \"torchvision_resnet50_swsl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/500},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/4000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/4000},\n",
    "              }\n",
    "\n",
    "# {\"lr\": optimizer_params[\"lr\"]/500}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ImageAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T06:54:57.243316Z",
     "start_time": "2020-07-05T06:54:57.236291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "        \n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18_ssl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/200},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/100},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "              }\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[{\"model\": \"torchvision_resnet18_ssl\", \"large_rf\": True, \"finetune\": True}], \n",
    "                              num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.2, dropout=0.2, \n",
    "                                                                                    embedding_dims=256, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=64, forward=\"get_word_vectors\")],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:58:28.524045Z",
     "start_time": "2020-07-05T06:54:57.244861Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 53m 12s 16061504 0.761\t0.733 -> resnet18\n",
    "# 53m 10s 16061504 0.751\t0.740 -> resnet18_swsl\n",
    "# 53m 12s 16061504 0.757\t0.745 -> resnet18_ssl\n",
    "# 53m 19s 16061504 0.783\t0.727 -> resnet18_swsl\n",
    "# 57m 20s 26240576 0.853\t0.687 -> resnet50_swsl\n",
    "# 59m 39s 25677632 0.820\t0.709 -> resnext50_32x4d_swsl\n",
    "# 1h 21m 0.741\t0.717 -> resnext50_32x4d_swsl\n",
    "# resnext50_32x4d_swsl resnext50_32x4d resnext101_32x8d_wsl resnet50_swsl resnet50_ssl resnext50_32x4d_ssl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Image Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T09:19:59.001282Z",
     "start_time": "2020-07-05T08:17:28.781151Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "        \n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18_ssl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/200},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/100},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "              }\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[{\"model\": \"torchvision_resnet18_ssl\", \"large_rf\": True, \"finetune\": True}], \n",
    "                              num_classes=2, \n",
    "                              text_models=[],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Detr Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T19:01:51.576590Z",
     "start_time": "2020-07-04T17:42:41.236714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "\n",
    "model_fn = model_builder(\n",
    "    MultiImageMultiTextAttentionEarlyFusionModel,\n",
    "    dict(\n",
    "        image_models=['detr_resnet50'],\n",
    "        num_classes=2,\n",
    "        text_models=[\n",
    "            dict(cls=Fasttext1DCNNModel,\n",
    "                 params=dict(\n",
    "                     classifier_dims=256,\n",
    "                     num_classes=2,\n",
    "                     n_tokens_out=16,\n",
    "                     n_layers=2,\n",
    "                     final_layer_builder=lambda *args: None,\n",
    "                     gaussian_noise=0.2,\n",
    "                     dropout=0.2,\n",
    "                     embedding_dims=256,\n",
    "                     internal_dims=256,\n",
    "                     featurizer=\"cnn\",\n",
    "                 ),\n",
    "                 in_channels=256,\n",
    "                 in_tokens=64,\n",
    "                 forward=\"get_word_vectors\")\n",
    "        ],\n",
    "        internal_dims=256,\n",
    "        classifier_dims=256,\n",
    "        n_tokens_out=16,\n",
    "        n_layers=2,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        gaussian_noise=0.3,\n",
    "        dropout=0.3,\n",
    "    ),\n",
    "    per_param_opts_fn=None,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "batch_size=128\n",
    "epochs = 10\n",
    "multi_eval = False\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    augmentation_weights=augmentation_weights,\n",
    "    kfold=kfold,\n",
    "    multi_eval=multi_eval,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Caption Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=['caption_features'], \n",
    "                              num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.2, dropout=0.2, \n",
    "                                                                                    embedding_dims=256, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=64, forward=\"get_word_vectors\")],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=None,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Text Multi Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-14T18:32:38.352Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model:  resnet18_ssl-contrastive.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocast =  True Epochs =  6 Divisor = 2 Examples = 3600 Batch Size =  64\n",
      "Training Samples =  7200 Weighted Sampling =  True Num Batches =  57 Accumulation steps =  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11da4b896c64fbd8542ffe3d0f479ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e52916a0232432ea8e5de046717c9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  1 Loss = 0.363838 LR = 0.00005588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156fc575708b4abd890a3635bbdb2919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  2 Loss = 0.336126 LR = 0.00009938\n",
      "Epoch =  2 Train = 0.707273 Val = 0.705154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf0e86e992f449ba5e57c6faf7e594b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  3 Loss = 0.330457 LR = 0.00008095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2e8ad45cbb47e0a73e97626baf49ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_fn = model_builder(\n",
    "    MultiImageMultiTextAttentionEarlyFusionModel,\n",
    "    dict(\n",
    "        image_models=[\n",
    "#             {\n",
    "#                 \"model\": 'caption_features',\n",
    "#                 \"gaussian_noise\": 0.0,\n",
    "#                 \"dropout\": 0.0\n",
    "#             },\n",
    "            {\n",
    "                \"model\": 'vgg_face',\n",
    "                \"gaussian_noise\": 0.0,\n",
    "                \"dropout\": 0.0,\n",
    "                \"finetune\": True,\n",
    "            },\n",
    "#             {\n",
    "#                 \"model\": 'detr_resnet50',\n",
    "#                 \"gaussian_noise\": 0.0,\n",
    "#                 \"dropout\": 0.0\n",
    "#             },\n",
    "#             {\n",
    "#                 \"model\": 'detr_resnet50_panoptic',\n",
    "#                 \"gaussian_noise\": 0.0,\n",
    "#                 \"dropout\": 0.0\n",
    "#             },\n",
    "            {\n",
    "                \"model\": \"torchvision_resnet18_ssl-contrastive\",\n",
    "                \"large_rf\": True,\n",
    "                \"finetune\": False\n",
    "            },\n",
    "        ],\n",
    "        num_classes=2,\n",
    "        text_models=[\n",
    "            dict(cls=Fasttext1DCNNModel,\n",
    "                 params=dict(\n",
    "                     classifier_dims=256,\n",
    "                     num_classes=2,\n",
    "                     n_tokens_in=64,\n",
    "                     n_tokens_out=16,\n",
    "                     n_layers=2,\n",
    "                     final_layer_builder=lambda *args: None,\n",
    "                     gaussian_noise=0.5,\n",
    "                     dropout=0.4,\n",
    "                     embedding_dims=256,\n",
    "                     internal_dims=256,\n",
    "                     featurizer=\"gru\",\n",
    "                 ),\n",
    "                 in_channels=256,\n",
    "                 in_tokens=64,\n",
    "                 forward=\"get_word_vectors\"),\n",
    "            dict(\n",
    "                cls=AlbertClassifer,\n",
    "                params=dict(classifier_dims=256,\n",
    "                              num_classes=2,\n",
    "                              embedding_dims=768,\n",
    "                              gaussian_noise=5.5,\n",
    "                              dropout=0.175,\n",
    "                              word_masking_proba=0.25,\n",
    "                              internal_dims=512,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              n_layers=2,\n",
    "                              n_encoders=2,\n",
    "                              n_decoders=2,\n",
    "                              n_tokens_in=96,\n",
    "                              n_tokens_out=16,\n",
    "                              featurizer=\"transformer\",\n",
    "                              model='./model-nsp',\n",
    "                              finetune=False),\n",
    "                in_channels=768,\n",
    "                in_tokens=96,\n",
    "                forward=\"get_word_vectors\",\n",
    "            )\n",
    "        ],\n",
    "        internal_dims=256,\n",
    "        classifier_dims=256,\n",
    "        n_tokens_out=32,\n",
    "        n_layers=2, n_encoders=2, n_decoders=2,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        gaussian_noise=0.75,\n",
    "        dropout=0.3,\n",
    "    ),\n",
    "    per_param_opts_fn=None,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "multi_eval = False\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    augmentation_weights=augmentation_weights,\n",
    "    kfold=kfold,\n",
    "    multi_eval=multi_eval,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    validation_epochs=[2, 5, 9, 11, 14, 17, 20, 23, 27], \n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    model_call_back=reg_sched,\n",
    ")\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187026Z",
     "start_time": "2020-06-18T08:58:40.596Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 1\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, augmentation_weights, scheduler_init_fn=scheduler_init_fn)\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187634Z",
     "start_time": "2020-06-18T08:58:40.600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
