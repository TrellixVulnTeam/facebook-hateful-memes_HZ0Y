{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:14:44.543101Z",
     "start_time": "2020-07-15T17:14:41.638498Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:14:44.669643Z",
     "start_time": "2020-07-15T17:14:44.545157Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "\n",
    "choice_probas = {\"keyboard\": 0.1, \"char_substitute\": 0.0, \"char_insert\": 0.1, \"char_swap\": 0.0, \"ocr\": 0.0, \"char_delete\": 0.1,\n",
    "                 \"fasttext\": 0.0, \"glove_twitter\": 0.0, \"glove_wiki\": 0.0, \"word2vec\": 0.0, \"split\": 0.1,\n",
    "                 \"stopword_insert\": 0.3, \"word_join\": 0.1, \"word_cutout\": 0.8,\n",
    "                 \"text_rotate\": 0.5, \"sentence_shuffle\": 0.5, \"one_third_cut\": 0.4, \"half_cut\":0.1}\n",
    "preprocess_text = TextAugment([0.0, 0.1, 0.05, 0.35, 0.3, 0.2], choice_probas, fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "\n",
    "augs_dict = dict(\n",
    "    grayscale=transforms.Grayscale(num_output_channels=3),\n",
    "    hflip=transforms.RandomHorizontalFlip(p=1.0),\n",
    "    rc2=transforms.Compose(\n",
    "        [transforms.Resize(480),\n",
    "         transforms.CenterCrop(400)]),\n",
    "    rotate=DefinedRotation(15),\n",
    "    affine=DefinedAffine(0, scale=(0.6, 0.6)),\n",
    "    translate1=DefinedAffine(0, translate=(0.25, 0.25)),\n",
    ")\n",
    "im_transform = ImageAugment(count_proba=[0.0, 1.0], augs_dict=augs_dict, choice_probas=\"uniform\")\n",
    "\n",
    "\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=preprocess_text, train_image_transform=im_transform, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = True, dev=False, \n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=True,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:14:44.681043Z",
     "start_time": "2020-07-15T17:14:44.671525Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T17:14:44.688463Z",
     "start_time": "2020-07-15T17:14:44.682556Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs = 25\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([5, 7, 10, 17], gamma=0.1) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "\n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/750},\n",
    "                                                      \"8\": {\"lr\": optimizer_params[\"lr\"]/250},\n",
    "                                                      \"lr\": optimizer_params[\"lr\"]/2000},\n",
    "                             \"torchvision_resnet50_swsl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/500},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/4000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/4000},\n",
    "              }\n",
    "\n",
    "# {\"lr\": optimizer_params[\"lr\"]/500}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ImageAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T06:54:57.243316Z",
     "start_time": "2020-07-05T06:54:57.236291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "        \n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18_ssl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/200},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/100},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "              }\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[{\"model\": \"torchvision_resnet18_ssl\", \"large_rf\": True, \"finetune\": True}], \n",
    "                              num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.2, dropout=0.2, \n",
    "                                                                                    embedding_dims=256, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=64, forward=\"get_word_vectors\")],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T07:58:28.524045Z",
     "start_time": "2020-07-05T06:54:57.244861Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 53m 12s 16061504 0.761\t0.733 -> resnet18\n",
    "# 53m 10s 16061504 0.751\t0.740 -> resnet18_swsl\n",
    "# 53m 12s 16061504 0.757\t0.745 -> resnet18_ssl\n",
    "# 53m 19s 16061504 0.783\t0.727 -> resnet18_swsl\n",
    "# 57m 20s 26240576 0.853\t0.687 -> resnet50_swsl\n",
    "# 59m 39s 25677632 0.820\t0.709 -> resnext50_32x4d_swsl\n",
    "# 1h 21m 0.741\t0.717 -> resnext50_32x4d_swsl\n",
    "# resnext50_32x4d_swsl resnext50_32x4d resnext101_32x8d_wsl resnet50_swsl resnet50_ssl resnext50_32x4d_ssl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Image Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T09:19:59.001282Z",
     "start_time": "2020-07-05T08:17:28.781151Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "        \n",
    "lr_strategy = {\"im_models\": {\"torchvision_resnet18_ssl\": {\"7\": {\"lr\": optimizer_params[\"lr\"]/200},\n",
    "                                                           \"8\": {\"lr\": optimizer_params[\"lr\"]/100},\n",
    "                                                           \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "                            \"lr\": optimizer_params[\"lr\"]/1000},\n",
    "              }\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=[{\"model\": \"torchvision_resnet18_ssl\", \"large_rf\": True, \"finetune\": True}], \n",
    "                              num_classes=2, \n",
    "                              text_models=[],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Detr Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T19:01:51.576590Z",
     "start_time": "2020-07-04T17:42:41.236714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "\n",
    "model_fn = model_builder(\n",
    "    MultiImageMultiTextAttentionEarlyFusionModel,\n",
    "    dict(\n",
    "        image_models=['detr_resnet50'],\n",
    "        num_classes=2,\n",
    "        text_models=[\n",
    "            dict(cls=Fasttext1DCNNModel,\n",
    "                 params=dict(\n",
    "                     classifier_dims=256,\n",
    "                     num_classes=2,\n",
    "                     n_tokens_out=16,\n",
    "                     n_layers=2,\n",
    "                     final_layer_builder=lambda *args: None,\n",
    "                     gaussian_noise=0.2,\n",
    "                     dropout=0.2,\n",
    "                     embedding_dims=256,\n",
    "                     internal_dims=256,\n",
    "                     featurizer=\"cnn\",\n",
    "                 ),\n",
    "                 in_channels=256,\n",
    "                 in_tokens=64,\n",
    "                 forward=\"get_word_vectors\")\n",
    "        ],\n",
    "        internal_dims=256,\n",
    "        classifier_dims=256,\n",
    "        n_tokens_out=16,\n",
    "        n_layers=2,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        gaussian_noise=0.3,\n",
    "        dropout=0.3,\n",
    "    ),\n",
    "    per_param_opts_fn=None,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "batch_size=128\n",
    "epochs = 10\n",
    "multi_eval = False\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    augmentation_weights=augmentation_weights,\n",
    "    kfold=kfold,\n",
    "    multi_eval=multi_eval,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Caption Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# {\"model\": \"torchvision_resnet18\", \"large_rf\": True, \"finetune\": True}\n",
    "\n",
    "model_fn = model_builder(MultiImageMultiTextAttentionEarlyFusionModel, \n",
    "                         dict(image_models=['caption_features'], \n",
    "                              num_classes=2, \n",
    "                              text_models=[dict(cls=Fasttext1DCNNModel, params=dict(classifier_dims=256, \n",
    "                                                                                    num_classes=2, n_tokens_out=16,\n",
    "                                                                                    n_layers=2, final_layer_builder=lambda *args: None,\n",
    "                                                                                    gaussian_noise=0.2, dropout=0.2, \n",
    "                                                                                    embedding_dims=256, internal_dims=256, featurizer=\"cnn\",),\n",
    "                                               in_channels=256, in_tokens=64, forward=\"get_word_vectors\")],\n",
    "                              internal_dims=256, classifier_dims=256,\n",
    "                              n_tokens_out=16, n_layers=2,\n",
    "                              final_layer_builder=fb_1d_loss_builder,\n",
    "                              gaussian_noise=0.2, dropout=0.2, ),\n",
    "                         per_param_opts_fn=None,\n",
    "                         optimiser_class=optimizer, optimiser_params=optimizer_params)\n",
    "\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "\n",
    "multi_eval=False \n",
    "kfold=False\n",
    "results, prfs = train_validate_ntimes(model_fn, data, batch_size, epochs, \n",
    "                                      augmentation_weights=augmentation_weights, \n",
    "                                      kfold=kfold, multi_eval=multi_eval,\n",
    "                                      scheduler_init_fn=scheduler_init_fn, \n",
    "                                      validation_epochs=[2, 4, 7, 9, 11, 14, 17, 20, 23])\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Text Multi Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T20:18:48.722Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model:  resnet18_ssl-contrastive.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Params = 92430082 \n",
      " MultiImageMultiTextAttentionEarlyFusionModel(\n",
      "  (torchvision_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (im_models): ModuleDict(\n",
      "    (torchvision_resnet18_ssl-contrastive): LambdaLayer(\n",
      "      (lambd): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (7): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (8): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (gaussian_noise): GaussianNoise()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (vgg_face): LambdaLayer(\n",
      "      (lambd): Sequential(\n",
      "        (0): Resnet50_256(\n",
      "          (conv1_7x7_s2): Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
      "          (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv1_relu_7x7_s2): ReLU(inplace=True)\n",
      "          (pool1_3x3_s2): MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
      "          (conv2_1_1x1_reduce): Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_1_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_1_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv2_1_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv2_1_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_1_3x3_relu): ReLU(inplace=True)\n",
      "          (conv2_1_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_1_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_1_1x1_proj): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_1_1x1_proj_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_1_relu): ReLU(inplace=True)\n",
      "          (conv2_2_1x1_reduce): Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_2_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_2_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv2_2_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv2_2_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_2_3x3_relu): ReLU(inplace=True)\n",
      "          (conv2_2_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_2_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_2_relu): ReLU(inplace=True)\n",
      "          (conv2_3_1x1_reduce): Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_3_1x1_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_3_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv2_3_3x3): Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv2_3_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_3_3x3_relu): ReLU(inplace=True)\n",
      "          (conv2_3_1x1_increase): Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv2_3_1x1_increase_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2_3_relu): ReLU(inplace=True)\n",
      "          (conv3_1_1x1_reduce): Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv3_1_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_1_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv3_1_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv3_1_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_1_3x3_relu): ReLU(inplace=True)\n",
      "          (conv3_1_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_1_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_1_1x1_proj): Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv3_1_1x1_proj_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_1_relu): ReLU(inplace=True)\n",
      "          (conv3_2_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_2_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_2_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv3_2_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv3_2_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_2_3x3_relu): ReLU(inplace=True)\n",
      "          (conv3_2_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_2_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_2_relu): ReLU(inplace=True)\n",
      "          (conv3_3_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_3_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_3_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv3_3_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv3_3_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_3_3x3_relu): ReLU(inplace=True)\n",
      "          (conv3_3_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_3_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_3_relu): ReLU(inplace=True)\n",
      "          (conv3_4_1x1_reduce): Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_4_1x1_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_4_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv3_4_3x3): Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv3_4_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_4_3x3_relu): ReLU(inplace=True)\n",
      "          (conv3_4_1x1_increase): Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv3_4_1x1_increase_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3_4_relu): ReLU(inplace=True)\n",
      "          (conv4_1_1x1_reduce): Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv4_1_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_1_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_1_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_1_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_1_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_1_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_1_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_1_1x1_proj): Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv4_1_1x1_proj_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_1_relu): ReLU(inplace=True)\n",
      "          (conv4_2_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_2_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_2_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_2_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_2_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_2_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_2_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_2_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_2_relu): ReLU(inplace=True)\n",
      "          (conv4_3_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_3_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_3_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_3_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_3_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_3_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_3_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_3_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_3_relu): ReLU(inplace=True)\n",
      "          (conv4_4_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_4_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_4_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_4_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_4_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_4_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_4_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_4_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_4_relu): ReLU(inplace=True)\n",
      "          (conv4_5_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_5_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_5_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_5_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_5_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_5_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_5_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_5_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_5_relu): ReLU(inplace=True)\n",
      "          (conv4_6_1x1_reduce): Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_6_1x1_reduce_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_6_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv4_6_3x3): Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv4_6_3x3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_6_3x3_relu): ReLU(inplace=True)\n",
      "          (conv4_6_1x1_increase): Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv4_6_1x1_increase_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv4_6_relu): ReLU(inplace=True)\n",
      "          (conv5_1_1x1_reduce): Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv5_1_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_1_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv5_1_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv5_1_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_1_3x3_relu): ReLU(inplace=True)\n",
      "          (conv5_1_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv5_1_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_1_1x1_proj): Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
      "          (conv5_1_1x1_proj_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_1_relu): ReLU(inplace=True)\n",
      "          (conv5_2_1x1_reduce): Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv5_2_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_2_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv5_2_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv5_2_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_2_3x3_relu): ReLU(inplace=True)\n",
      "          (conv5_2_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv5_2_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_2_relu): ReLU(inplace=True)\n",
      "          (conv5_3_1x1_reduce): Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv5_3_1x1_reduce_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_3_1x1_reduce_relu): ReLU(inplace=True)\n",
      "          (conv5_3_3x3): Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (conv5_3_3x3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_3_3x3_relu): ReLU(inplace=True)\n",
      "          (conv5_3_1x1_increase): Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
      "          (conv5_3_1x1_increase_bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv5_3_relu): ReLU(inplace=True)\n",
      "          (pool5_7x7_s1): AdaptiveAvgPool2d(output_size=1)\n",
      "          (feat_extract): Conv2d(2048, 256, kernel_size=[1, 1], stride=(1, 1))\n",
      "        )\n",
      "        (1): LambdaLayer(\n",
      "          (gaussian_noise): GaussianNoise()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (gaussian_noise): GaussianNoise()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (post_procs): ModuleDict(\n",
      "    (torchvision_resnet18_ssl-contrastive): LambdaLayer(\n",
      "      (gaussian_noise): GaussianNoise()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (vgg_face): Identity()\n",
      "    (tx_0): Sequential(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): GaussianNoise()\n",
      "    )\n",
      "    (tx_1): Sequential(\n",
      "      (0): Dropout(p=0.0, inplace=False)\n",
      "      (1): GaussianNoise()\n",
      "    )\n",
      "  )\n",
      "  (tx_models): ModuleDict(\n",
      "    (tx_0): Fasttext1DCNNModel(\n",
      "      (crawl_nn): ExpandContract(\n",
      "        (nn): Sequential(\n",
      "          (0): Transpose()\n",
      "          (1): Dropout(p=0.4, inplace=False)\n",
      "          (2): Conv1d(600, 512, kernel_size=(1,), stride=(1,), groups=8, bias=False)\n",
      "          (3): LeakyReLU(negative_slope=0.01)\n",
      "          (4): Dropout(p=0.4, inplace=False)\n",
      "          (5): Conv1d(512, 256, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
      "          (6): Transpose()\n",
      "          (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (tx_1): AlbertClassifer(\n",
      "      (model): RobertaModel(\n",
      "        (embeddings): RobertaEmbeddings(\n",
      "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "          (token_type_embeddings): Embedding(1, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (featurizer): TransformerEnsembleFeaturizer(\n",
      "    (ensemble_inp): ModuleDict(\n",
      "      (torchvision_resnet18_ssl-contrastive): Sequential(\n",
      "        (0): Dropout(p=0.3, inplace=False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=8)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (tx_0): Sequential(\n",
      "        (0): Dropout(p=0.3, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (tx_1): Sequential(\n",
      "        (0): Dropout(p=0.3, inplace=False)\n",
      "        (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (vgg_face): Sequential(\n",
      "        (0): Dropout(p=0.3, inplace=False)\n",
      "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01)\n",
      "        (3): GaussianNoise()\n",
      "        (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norms): ModuleDict(\n",
      "      (torchvision_resnet18_ssl-contrastive): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (tx_0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (tx_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (vgg_face): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (gaussian_noise): GaussianNoise()\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.3, inplace=False)\n",
      "            (dropout2): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.3, inplace=False)\n",
      "            (dropout2): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.3, inplace=False)\n",
      "            (dropout2): Dropout(p=0.3, inplace=False)\n",
      "            (dropout3): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.3, inplace=False)\n",
      "            (dropout2): Dropout(p=0.3, inplace=False)\n",
      "            (dropout3): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (pos_encoder2d): PositionalEncoding2D(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (global_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (final_layer): MultiTaskForward(\n",
      "    (heads): ModuleList(\n",
      "      (0): CNNHead(\n",
      "        (loss): CrossEntropyLoss()\n",
      "        (classifier): Sequential(\n",
      "          (0): Dropout(p=0.3, inplace=False)\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01)\n",
      "          (3): Transpose()\n",
      "          (4): Conv1d(256, 2, kernel_size=(32,), stride=(1,))\n",
      "          (5): AdaptiveAvgPool1d(output_size=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Autocast =  True Epochs =  10 Divisor = 2 Examples = 3600 Batch Size =  64\n",
      "Training Samples =  7200 Weighted Sampling =  True Num Batches =  57 Accumulation steps =  4\n",
      "[WARN]: Number of training batches not divisible by accumulation steps, some training batches will be wasted due to this.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ae6704706b4eb385a702499e35901d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f1072205bf4acb8387ebc18264f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  1 Loss = 0.246657 LR = 0.00003333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103ef8979b184ba3a1b44d8dc1a1c90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  2 Loss = 0.228906 LR = 0.00006667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f92cbc6fc04f579d52d0f35bf789fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  3 Loss = 0.219330 LR = 0.00010000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc99962d599483f9ca1dfb54f8bc330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  4 Loss = 0.210530 LR = 0.00009505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c181ecd0e5834a18bcf54ea06faa7750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch =  5 Loss = 0.190959 LR = 0.00008117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a797180ade34409b0f0544167b7aebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_strategy = {\n",
    "    \"im_models\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "        \"torchvision_resnet18_ssl-contrastive\": {\n",
    "            \"lambd\": {\n",
    "                \"8\": {\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            },\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "        \"vgg_face\": {\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"lambd\": {\n",
    "                \"0\": {\n",
    "                    \"feat_extract\": {\n",
    "                        \"finetune\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"finetune\": False,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "model_fn = model_builder(\n",
    "    MultiImageMultiTextAttentionEarlyFusionModel,\n",
    "    dict(\n",
    "        image_models=[\n",
    "            #             {\n",
    "            #                 \"model\": 'caption_features',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            {\n",
    "                \"model\": 'vgg_face',\n",
    "                \"gaussian_noise\": 0.0,\n",
    "                \"dropout\": 0.0,\n",
    "            },\n",
    "            #             {\n",
    "            #                 \"model\": 'detr_resnet50',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            #             {\n",
    "            #                 \"model\": 'detr_resnet50_panoptic',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            {\n",
    "                \"model\": \"torchvision_resnet18_ssl-contrastive\",\n",
    "                \"large_rf\": True,\n",
    "            },\n",
    "        ],\n",
    "        num_classes=2,\n",
    "        text_models=[\n",
    "            dict(cls=Fasttext1DCNNModel,\n",
    "                 params=dict(\n",
    "                     classifier_dims=256,\n",
    "                     num_classes=2,\n",
    "                     n_tokens_in=64,\n",
    "                     n_tokens_out=16,\n",
    "                     n_layers=2,\n",
    "                     final_layer_builder=lambda *args: None,\n",
    "                     gaussian_noise=0.5,\n",
    "                     dropout=0.4,\n",
    "                     embedding_dims=256,\n",
    "                     internal_dims=256,\n",
    "                     featurizer=\"gru\",\n",
    "                 ),\n",
    "                 in_channels=256,\n",
    "                 in_tokens=64,\n",
    "                 forward=\"get_word_vectors\"),\n",
    "            dict(\n",
    "                cls=AlbertClassifer,\n",
    "                params=dict(classifier_dims=256,\n",
    "                            num_classes=2,\n",
    "                            embedding_dims=768,\n",
    "                            gaussian_noise=5.5,\n",
    "                            dropout=0.175,\n",
    "                            word_masking_proba=0.25,\n",
    "                            internal_dims=512,\n",
    "                            final_layer_builder=fb_1d_loss_builder,\n",
    "                            n_layers=2,\n",
    "                            n_encoders=2,\n",
    "                            n_decoders=2,\n",
    "                            n_tokens_in=96,\n",
    "                            n_tokens_out=16,\n",
    "                            featurizer=\"transformer\",\n",
    "                            model='./model-nsp',\n",
    "                            loss=\"focal\",\n",
    "                            dice_loss_coef=0.0,\n",
    "                            auc_loss_coef=0.0,\n",
    "                            finetune=False),\n",
    "                in_channels=768,\n",
    "                in_tokens=96,\n",
    "                forward=\"get_word_vectors\",\n",
    "            )\n",
    "        ],\n",
    "        internal_dims=256,\n",
    "        classifier_dims=256,\n",
    "        n_tokens_out=32,\n",
    "        n_layers=2,\n",
    "        n_encoders=2,\n",
    "        n_decoders=2,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        gaussian_noise=0.75,\n",
    "        dropout=0.3,\n",
    "    ),\n",
    "    per_param_opts_fn=lr_strategy,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    validation_epochs=[7, 11, 14, 17, 20, 23, 27],\n",
    "    show_model_stats=True,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    accumulation_steps=4,\n",
    "    model_call_back=reg_sched,\n",
    ")\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187026Z",
     "start_time": "2020-06-18T08:58:40.596Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 1\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, augmentation_weights, scheduler_init_fn=scheduler_init_fn)\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T08:58:43.187634Z",
     "start_time": "2020-06-18T08:58:40.600Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
