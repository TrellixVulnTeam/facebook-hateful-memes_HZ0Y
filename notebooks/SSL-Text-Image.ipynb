{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:01:19.139776Z",
     "start_time": "2020-08-14T20:01:15.658923Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import random\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, random_word_mask, dict2sampleList, run_simclr, load_stored_params\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine, HalfSwap, get_image_transforms, get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.preprocessing import NegativeSamplingDataset, ImageFolderDataset, ZipDatasets\n",
    "from facebook_hateful_memes_detector.models.MultiModal.VilBertVisualBert import VilBertVisualBertModel\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "from facebook_hateful_memes_detector.utils import get_vgg_face_model, get_torchvision_classification_models, init_fc, my_collate, merge_sample_lists\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "# Use mixup in SSL training, Use UDA maybe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:01:19.269718Z",
     "start_time": "2020-08-14T20:01:19.141682Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preprocess_text():\n",
    "    char_level = {\n",
    "        \"keyboard\": 0.1,\n",
    "        \"char_substitute\": 0.4,\n",
    "        \"char_insert\": 0.2,\n",
    "        \"char_swap\": 0.2,\n",
    "        \"ocr\": 0.0,\n",
    "        \"char_delete\": 0.1\n",
    "    }\n",
    "    char_level = TextAugment([0.1, 0.8, 0.1], char_level)\n",
    "    word_level = {\n",
    "        \"fasttext\": 0.0,\n",
    "        \"glove_twitter\": 0.0,\n",
    "        \"glove_wiki\": 0.0,\n",
    "        \"word2vec\": 0.0,\n",
    "        \"split\": 0.2,\n",
    "        \"stopword_insert\": 0.0,\n",
    "        \"word_join\": 0.2,\n",
    "        \"word_cutout\": 0.8,\n",
    "        \"gibberish_insert\": 0.0\n",
    "    }\n",
    "    word_level = TextAugment([0.2, 0.7, 0.1], word_level)\n",
    "    sentence_level = {\n",
    "        \"text_rotate\": 0.0,\n",
    "        \"sentence_shuffle\": 0.0,\n",
    "        \"one_third_cut\": 0.3,\n",
    "        \"half_cut\": 0.0,\n",
    "        \"part_select\": 0.75\n",
    "    }\n",
    "    sentence_level = TextAugment([0.75, 0.25], sentence_level)\n",
    "    gibberish = {\n",
    "        \"gibberish_insert\": 0.25,\n",
    "        \"punctuation_insert\": 0.75,\n",
    "    }\n",
    "    gibberish = TextAugment([0.75, 0.25], gibberish)\n",
    "\n",
    "    def process(text):\n",
    "        text = sentence_level(text)\n",
    "        text = word_level(text)\n",
    "        text = char_level(text)\n",
    "        text = gibberish(text)\n",
    "        return text\n",
    "\n",
    "    return process\n",
    "\n",
    "\n",
    "preprocess_text = get_preprocess_text()\n",
    "transforms_for_bbox_methods = get_transforms_for_bbox_methods()\n",
    "\n",
    "preprocess_easy = transforms.Compose([\n",
    "    get_image_transforms(mode=\"easy\"),\n",
    "    get_image2torchvision_transforms(),\n",
    "])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    get_image_transforms(mode=\"hard\"),\n",
    "    get_image2torchvision_transforms(),\n",
    "])\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\",\n",
    "                    train_text_transform=preprocess_text,\n",
    "                    train_image_transform=transforms_for_bbox_methods,\n",
    "                    test_text_transform=None,\n",
    "                    test_image_transform=None,\n",
    "                    train_torchvision_image_transform=None,\n",
    "                    test_torchvision_image_transform=None,\n",
    "                    train_torchvision_pre_image_transform=None,\n",
    "                    test_torchvision_pre_image_transform=None,\n",
    "                    cache_images=True,\n",
    "                    use_images=True,\n",
    "                    dev=False,\n",
    "                    test_dev=True,\n",
    "                    keep_original_text=True,\n",
    "                    keep_original_image=True,\n",
    "                    keep_processed_image=True,\n",
    "                    keep_torchvision_image=False,\n",
    "                    train_mixup_config=dict(proba=0.0))\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat((data[\"train\"].drop(columns=[\"label\"]),\n",
    "                data[\"dev\"].drop(columns=[\"label\"]), data[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:03:45.645241Z",
     "start_time": "2020-08-14T20:01:19.271924Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = convert_dataframe_to_dataset(df, data[\"metadata\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:03:45.649839Z",
     "start_time": "2020-08-14T20:03:45.647170Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLM for TextImage, AugSim for All\n",
    "\n",
    "# data = get_datasets(data_dir=\"../data/\",\n",
    "#                     train_text_transform=None,\n",
    "#                     train_image_transform=None,\n",
    "#                     test_text_transform=None,\n",
    "#                     test_image_transform=None,\n",
    "#                     train_torchvision_image_transform=None,\n",
    "#                     test_torchvision_image_transform=None,\n",
    "#                     train_torchvision_pre_image_transform=None,\n",
    "#                     test_torchvision_pre_image_transform=None,\n",
    "#                     cache_images=True,\n",
    "#                     use_images=True,\n",
    "#                     dev=False,\n",
    "#                     test_dev=True,\n",
    "#                     keep_original_text=True,\n",
    "#                     keep_original_image=True,\n",
    "#                     keep_processed_image=True,\n",
    "#                     keep_torchvision_image=False,\n",
    "#                     train_mixup_config=dict(proba=0.0))\n",
    "# dataset = convert_dataframe_to_dataset(df, data[\"metadata\"], True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:03:45.658518Z",
     "start_time": "2020-08-14T20:03:45.651430Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorized_text_processor = np.vectorize(preprocess_text)\n",
    "\n",
    "def torch_vectorize(fn):\n",
    "    def vfn(elements):\n",
    "        elements = [fn(e) for e in elements]\n",
    "        return torch.stack(elements)# .type(torch.cuda.HalfTensor)\n",
    "    return vfn\n",
    "\n",
    "preprocess_torchvision_image = torch_vectorize(preprocess)\n",
    "\n",
    "def vectorized_image_processor(images):\n",
    "    return [transforms_for_bbox_methods(i) for i in images]\n",
    "\n",
    "def augment_method(sampleList):\n",
    "    sampleList = dict2sampleList(sampleList, device=get_device())\n",
    "    sampleList = sampleList.copy()\n",
    "    if \"torchvision_image\" in sampleList:\n",
    "        sampleList.torchvision_image = preprocess_torchvision_image(sampleList.original_image)\n",
    "    sampleList.image = vectorized_image_processor(sampleList.original_image)\n",
    "    sampleList.text = vectorized_text_processor(sampleList.original_text)\n",
    "    sampleList.mixup = [False] * len(sampleList.text)\n",
    "    sampleList = sampleList.to(get_device())\n",
    "    return sampleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:17:09.857466Z",
     "start_time": "2020-08-09T19:17:08.427340Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.show_mixup(5000) # 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:05.319881Z",
     "start_time": "2020-08-14T20:03:45.660627Z"
    }
   },
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    model_name={\"lxmert\": dict(dropout=0.05, gaussian_noise=0.01)},\n",
    "    num_classes=2,\n",
    "    gaussian_noise=0.0,\n",
    "    dropout=0.0,\n",
    "    word_masking_proba=0.1,\n",
    "    featurizer=\"pass\",\n",
    "    final_layer_builder=fb_1d_loss_builder,\n",
    "    internal_dims=768,\n",
    "    classifier_dims=768,\n",
    "    n_tokens_in=96,\n",
    "    n_tokens_out=96,\n",
    "    n_layers=0,\n",
    "    attention_drop_proba=0.0,\n",
    "    loss=\"focal\",\n",
    "    dice_loss_coef=0.0,\n",
    "    auc_loss_coef=0.0,\n",
    "    bbox_swaps=1,\n",
    "    bbox_copies=1,\n",
    "    bbox_gaussian_noise=0.0,\n",
    "    finetune=False)\n",
    "\n",
    "model_class = VilBertVisualBertModel\n",
    "model = model_class(**model_params)\n",
    "model.to(get_device())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:45:26.032249Z",
     "start_time": "2020-08-09T09:45:25.782526Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params = dict(lr=1e-4, weight_decay=1e-2)\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import MLMPretraining\n",
    "mlm_model = MLMPretraining(model, model.text_processor._tokenizer, 768, \"relu\", 96)\n",
    "mlm_model = mlm_model.to(get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T13:19:45.112463Z",
     "start_time": "2020-08-09T11:39:49.993000Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"finetune\": False,\n",
    "    },\n",
    "    \"mlm\": {\n",
    "        \"finetune\": True\n",
    "    }\n",
    "}\n",
    "epochs = 3\n",
    "batch_size = 128\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "\n",
    "_ = group_wise_finetune(mlm_model, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(mlm_model, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n",
    "                                     model_call_back=None, accumulation_steps=4, plot=True,\n",
    "                                     sampling_policy=None, class_weights=None)\n",
    "\n",
    "\n",
    "\n",
    "mlm_model.plot_loss_acc_hist()\n",
    "mlm_model.test_accuracy(batch_size, dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T11:24:41.962482Z",
     "start_time": "2020-08-09T11:24:41.960247Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(mlm_model.state_dict(), \"lxmert-mlm-init.pth\")\n",
    "# mlm_model.load_state_dict(torch.load(\"lxmert-mlm-init.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:58:06.163460Z",
     "start_time": "2020-08-09T15:05:22.244073Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 5\n",
    "batch_size = 48\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"lr\": optimizer_params[\"lr\"]\n",
    "    },\n",
    "    \"mlm\": {\n",
    "        \"finetune\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "_ = group_wise_finetune(mlm_model, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(mlm_model, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n",
    "                                     model_call_back=None, accumulation_steps=5, plot=True,\n",
    "                                     sampling_policy=None, class_weights=None)\n",
    "\n",
    "\n",
    "\n",
    "mlm_model.plot_loss_acc_hist()\n",
    "acc = mlm_model.test_accuracy(batch_size, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:45:15.996131Z",
     "start_time": "2020-07-31T04:14:22.512090Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = mlm_model.test_accuracy(batch_size, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:12:59.352087Z",
     "start_time": "2020-08-09T19:12:51.954015Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(mlm_model.model.state_dict(), \"lxmert-mlm.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# AugSim\n",
    "- Combine both unimodal and bimodal augsim using `random.random`\n",
    "- Take hints from SimCLR\n",
    "- We can do Text x Image (TODO: CrissCrossDataset for Augsim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:18:06.984384Z",
     "start_time": "2020-08-09T19:18:06.364731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_stored_params(model, \"lxmert-mlm.pth\")\n",
    "set_global(\"cache_allow_writes\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:18:22.043392Z",
     "start_time": "2020-08-09T19:18:22.039762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "optimizer_class = adamw\n",
    "optimizer_params = adamw_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T05:01:29.487245Z",
     "start_time": "2020-08-09T19:18:35.086830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "_ = group_wise_finetune(model, lr_strategy_model)\n",
    "params_conf, _ = group_wise_lr(model, lr_strategy_model)\n",
    "optim = optimizer_class(params_conf, **optimizer_params)\n",
    "\n",
    "_ = train_for_augment_similarity(model,\n",
    "                                 optim,\n",
    "                                 scheduler_init_fn,\n",
    "                                 batch_size,\n",
    "                                 epochs,\n",
    "                                 dataset,\n",
    "                                 augment_method=augment_method,\n",
    "                                 model_call_back=None,\n",
    "                                 collate_fn=my_collate,\n",
    "                                 accumulation_steps=4,\n",
    "                                 plot=True)\n",
    "# 0.001580, 0.000527\n",
    "# Try Augsim with L2 normed / LayerNormed vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T06:34:49.734072Z",
     "start_time": "2020-08-10T06:34:47.808602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lxmert-augsim.pth\")\n",
    "# model.load_state_dict(torch.load(\"lxmert-augsim.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR style or Differentiator\n",
    "- Combine Unimodal and Bimodal with probability\n",
    "- In unimodal differentiator we only change either text or image\n",
    "- Ability to use non-overlapping image sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.453139Z",
     "start_time": "2020-08-14T20:04:05.321942Z"
    }
   },
   "outputs": [],
   "source": [
    "load_stored_params(model, \"lxmert-smclr.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.459375Z",
     "start_time": "2020-08-14T20:04:06.455212Z"
    }
   },
   "outputs": [],
   "source": [
    "from facebook_hateful_memes_detector.utils import SimCLR\n",
    "\n",
    "def simclr_aug(sampleList):\n",
    "    sampleList = augment_method(sampleList.copy())\n",
    "    s2 = sampleList.copy()\n",
    "    s2.text = list(reversed(s2.text))\n",
    "    s = merge_sample_lists(sampleList, s2)\n",
    "    return s\n",
    "\n",
    "# set_global(\"cache_allow_writes\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.477539Z",
     "start_time": "2020-08-14T20:04:06.461220Z"
    }
   },
   "outputs": [],
   "source": [
    "smclr = SimCLR(model, 768, 256, 0.05, simclr_aug, simclr_aug)\n",
    "smclr = smclr.to(get_device())\n",
    "\n",
    "lr_strategy_pre = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "lr_strategy_post = {\n",
    "    \"finetune\": True,\n",
    "}\n",
    "\n",
    "pre_lr, post_lr = 5e-5, 5e-5\n",
    "pre_batch_size, post_batch_size = 256, 32\n",
    "pre_epochs, full_epochs = 2, 5\n",
    "collate_fn = my_collate\n",
    "\n",
    "def simclr_aug(sampleList):\n",
    "    sampleList = augment_method(sampleList.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-14T20:02:10.067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = run_simclr(smclr, dataset, dataset, lr_strategy_pre, lr_strategy_post, pre_lr, post_lr,\n",
    "           pre_batch_size, post_batch_size, pre_epochs, full_epochs,\n",
    "           collate_fn)\n",
    "\n",
    "res\n",
    "\n",
    "# 0.3268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:00:29.595925Z",
     "start_time": "2020-08-14T20:00:22.646123Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lxmert-smclr.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
