{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:59:42.537876Z",
     "start_time": "2020-08-09T09:59:39.033990Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import random\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, random_word_mask, my_collate, run_simclr\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, HalfSwap, get_image_transforms, get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.preprocessing import NegativeSamplingDataset, ImageFolderDataset, ZipDatasets\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "from facebook_hateful_memes_detector.utils import get_vgg_face_model, get_torchvision_classification_models, init_fc\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:59:42.546160Z",
     "start_time": "2020-08-09T09:59:42.541190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:59:48.989866Z",
     "start_time": "2020-08-09T09:59:48.980707Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms_for_bbox_methods = get_transforms_for_bbox_methods()\n",
    "\n",
    "preprocess_easy = transforms.Compose([\n",
    "    get_image_transforms(mode=\"easy\"),\n",
    "    get_image2torchvision_transforms(),\n",
    "])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    get_image_transforms(mode=\"hard\"),\n",
    "    get_image2torchvision_transforms(),\n",
    "])\n",
    "\n",
    "# AveragePooling MaxPooling Spatter Cutout CoarseDropout AdditiveGaussianNoise\n",
    "\n",
    "def torch_vectorize(fn):\n",
    "    def vfn(elements):\n",
    "        elements = [fn(e) for e in elements]\n",
    "        return torch.stack(elements)# .type(torch.cuda.HalfTensor)\n",
    "    return vfn\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:59:50.048740Z",
     "start_time": "2020-08-09T09:59:50.043565Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=1e-4, momentum=0.9, dampening=0, weight_decay=1e-4, nesterov=False)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Augmented/Masked Image same as Original Image - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.290243Z",
     "start_time": "2020-07-14T10:43:53.284899Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "class ImageVectorizer(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        images = images.type(torch.cuda.HalfTensor)\n",
    "        output = self.pool(self.model(images)).squeeze()\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.298600Z",
     "start_time": "2020-07-14T10:43:53.291631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_training(model_name, epochs = 10, batch_size = 256):\n",
    "    im_model = get_torchvision_classification_models(model_name, finetune=True)[0]\n",
    "    dataset_org = torch.utils.data.ConcatDataset([ImageFolderDataset(\"../data/img/\", image_transform=get_image2torchvision_transforms()),\n",
    "                                                  ImageFolderDataset(\"../data/img/\", image_transform=get_image2torchvision_transforms())])\n",
    "    dataset_mod = torch.utils.data.ConcatDataset([ImageFolderDataset(\"../data/img/\", image_transform=preprocess_easy),\n",
    "                                                  ImageFolderDataset(\"../data/img/\", image_transform=preprocess)])\n",
    "\n",
    "    zipped_dataset = ZipDatasets([dataset_org, dataset_mod])\n",
    "    \n",
    "    model_fn = model_builder(ImageVectorizer,\n",
    "                         dict(model=im_model),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "    model, optim = model_fn()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _ = train_for_augment_similarity(model,\n",
    "                                     optim,\n",
    "                                     scheduler_init_fn,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     zipped_dataset,\n",
    "                                     augment_method=lambda x: x,\n",
    "                                     model_call_back=None,\n",
    "                                     accumulation_steps=1,\n",
    "                                     collate_fn=None,\n",
    "                                     plot=True)\n",
    "    torch.save(model.model.state_dict(), \"%s-augsim.pth\" % model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.303541Z",
     "start_time": "2020-07-14T10:43:53.300543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(model.model.state_dict(), \"resnet18-augsim.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Contrastive Training / Distinguish between positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:54.610864Z",
     "start_time": "2020-07-14T10:43:54.601079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "class ImageDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, model, dims):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        layer1 = nn.Linear(dims * 2, dims)\n",
    "        init_fc(layer1, \"leaky_relu\")\n",
    "        layer2 = nn.Linear(dims, 2)\n",
    "        init_fc(layer2, \"linear\")\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.LayerNorm(dims * 2), \n",
    "                                        layer1, nn.LeakyReLU(), GaussianNoise(0.5), layer2)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        anchor, other, labels = data\n",
    "        anchor = anchor.type(torch.cuda.HalfTensor)\n",
    "        other = other.type(torch.cuda.HalfTensor)\n",
    "        \n",
    "        anchor_out = self.pool(self.model(anchor)).squeeze()\n",
    "        other_out = self.pool(self.model(other)).squeeze()\n",
    "        features = torch.cat([anchor_out, other_out], 1)\n",
    "        logits = self.classifier(features).squeeze()\n",
    "        loss = self.loss(logits, labels.to(get_device()).long())\n",
    "        logits = torch.softmax(logits, dim=1)\n",
    "        return logits, features, features, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:54.872234Z",
     "start_time": "2020-07-14T10:43:54.861180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def contrastive_training(model_name,\n",
    "                         epochs=1,\n",
    "                         batch_size=256,\n",
    "                         cache_images=True,\n",
    "                         dev=True):\n",
    "    optimizer = sgd\n",
    "    optimizer_params = sgd_params\n",
    "    im_model, shapes = get_torchvision_classification_models(\"%s-augsim\" %\n",
    "                                                             model_name,\n",
    "                                                             finetune=True)\n",
    "    model_fn = model_builder(ImageDiscriminator,\n",
    "                             dict(model=im_model, dims=shapes[0]),\n",
    "                             per_param_opts_fn=lr_strategy,\n",
    "                             optimiser_class=optimizer,\n",
    "                             optimiser_params=optimizer_params)\n",
    "\n",
    "    model, optim = model_fn()\n",
    "\n",
    "    if cache_images:\n",
    "        orig = ImageFolderDataset(\n",
    "            \"../data/img/\",\n",
    "            image_transform=get_image2torchvision_transforms(),\n",
    "            cache_images=True)\n",
    "        mods = ImageFolderDataset.from_images(orig.images,\n",
    "                                              image_transform=preprocess)\n",
    "        dataset = torch.utils.data.ConcatDataset([orig, mods])\n",
    "    else:\n",
    "        orig = ImageFolderDataset(\n",
    "            \"../data/img/\",\n",
    "            image_transform=get_image2torchvision_transforms(),\n",
    "            cache_images=False)\n",
    "        mods = ImageFolderDataset(\"../data/img/\",\n",
    "                                  image_transform=preprocess,\n",
    "                                  cache_images=False)\n",
    "        dataset = torch.utils.data.ConcatDataset([orig, mods])\n",
    "\n",
    "    if dev:\n",
    "        dataset, _ = torch.utils.data.random_split(dataset, [6_000, 14_000])\n",
    "        \n",
    "    dataset = NegativeSamplingDataset(dataset, negative_proportion=4)\n",
    "\n",
    "    train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "        dataset, [int(0.8 * len(dataset)),\n",
    "                  int(0.2 * len(dataset))])\n",
    "\n",
    "    train_losses, learning_rates = train(model,\n",
    "                                         optim,\n",
    "                                         scheduler_init_fn,\n",
    "                                         batch_size,\n",
    "                                         epochs,\n",
    "                                         train_dataset,\n",
    "                                         model_call_back=None,\n",
    "                                         accumulation_steps=1,\n",
    "                                         validation_strategy=None,\n",
    "                                         plot=True,\n",
    "                                         collate_fn=None,\n",
    "                                         sampling_policy=None,\n",
    "                                         class_weights=None)\n",
    "    metrics = [\"map\", \"acc\", \"auc\"]\n",
    "    val_metrics = validate(model,\n",
    "                           batch_size,\n",
    "                           validation_dataset,\n",
    "                           collate_fn=None)[0]\n",
    "    if not dev:\n",
    "        torch.save(model.model.state_dict(), \"%s-contrastive.pth\" % model_name)\n",
    "    return dict(val=dict(zip(metrics, val_metrics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR\n",
    "\n",
    "- Try Non overlapping image part Aug1, Aug2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T10:02:09.663448Z",
     "start_time": "2020-08-09T09:59:55.691384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb02a7cfb1645b18d8f446edfa8782c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from facebook_hateful_memes_detector.utils import SimCLR\n",
    "from facebook_hateful_memes_detector.utils.ImageModelShims import ImageModelShim, ImageCaptioningShim\n",
    "\n",
    "\n",
    "dataset = ImageFolderDataset(\"../data/img/\",\n",
    "                             image_transform=lambda x: x,\n",
    "                             cache_images=True)\n",
    "def collate_fn(batch):\n",
    "    return list(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T11:22:02.054376Z",
     "start_time": "2020-08-08T11:21:56.109355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model:  resnet50_ssl-contrastive.pth\n",
      "Loading saved model:  resnet50_ssl-contrastive.pth\n"
     ]
    }
   ],
   "source": [
    "# For Resnet Image Contrastive models\n",
    "preprocess_vec = torch_vectorize(preprocess)\n",
    "preprocess_easy_vec = torch_vectorize(preprocess_easy)\n",
    "model = ImageModelShim(resnet=\"resnet50_ssl-contrastive.pth\",dropout=0.1, gaussian_noise=0.01, attention_drop_proba=0.05)\n",
    "smclr = SimCLR(model, 768, 256, 0.1, preprocess_vec, preprocess_easy_vec)\n",
    "smclr = smclr.to(get_device())\n",
    "pre_batch_size = 128\n",
    "post_batch_size = 128\n",
    "pre_epochs = 2\n",
    "full_epochs = 10\n",
    "lr_strategy_pre = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"resnet_model\": {\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "        \"vgg_model\": {\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "lr_strategy_post = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"resnet_model\": {\n",
    "            \"finetune\": False,\n",
    "            \"6\": {\n",
    "                \"finetune\": True,\n",
    "            },\n",
    "            \"7\": {\n",
    "                \"finetune\": True,\n",
    "            },\n",
    "            \"8\": {\n",
    "                \"finetune\": True,\n",
    "            }\n",
    "        },\n",
    "        \"vgg_model\": {\n",
    "            \"0\": {\n",
    "                \"feat_extract\": {\n",
    "                   \"finetune\": True, \n",
    "                }\n",
    "            },\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "pre_lr, post_lr = 5e-5, 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T10:02:14.824340Z",
     "start_time": "2020-08-09T10:02:09.665066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/local/home/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    }
   ],
   "source": [
    "# Image Captioning\n",
    "\n",
    "def preprocess_vec(images):\n",
    "    return [transforms_for_bbox_methods(i) for i in images]\n",
    "\n",
    "model = ImageCaptioningShim(dropout=0.1)\n",
    "smclr = SimCLR(model, 768, 256, 0.1, preprocess_vec, preprocess_vec)\n",
    "smclr = smclr.to(get_device())\n",
    "set_global(\"cache_allow_writes\", True)\n",
    "pre_batch_size = 128\n",
    "post_batch_size = 128\n",
    "pre_epochs = 0\n",
    "full_epochs = 20\n",
    "\n",
    "lr_strategy_pre = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "    },\n",
    "}\n",
    "lr_strategy_post = lr_strategy_pre\n",
    "pre_lr, post_lr = 5e-5, 5e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T10:02:14.828510Z",
     "start_time": "2020-08-09T10:02:14.826299Z"
    }
   },
   "outputs": [],
   "source": [
    "# DETR\n",
    "# TODO:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-09T10:00:40.676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocast =  True Epochs =  20 Divisor = 1 Examples = 10000 Batch Size =  128\n",
      "Training Samples =  10000 Weighted Sampling =  False Num Batches =  79 Accumulation steps =  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7450afee526246829e4b8f4a2881bf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdcfb0cab114206a09504b4956bfac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=79.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCaptionFeatures : Loaded Model...\n",
      "FeatureExtractor : Loaded Model...\n",
      "\n",
      "Epoch =  1 Loss = 4.642441 LR = 0.00000833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd57c21c3dd4cfb84077f0e034498d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=79.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pre_dataset, post_dataset = dataset, dataset\n",
    "\n",
    "run_simclr(smclr, pre_dataset, post_dataset, lr_strategy_pre, lr_strategy_post,\n",
    "           pre_lr, post_lr, pre_batch_size, post_batch_size, pre_epochs,\n",
    "           full_epochs, collate_fn)\n",
    "\n",
    "# 0.7976, 0.9591\n",
    "# 0.7983, 0.9576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-08T10:09:26.796333Z",
     "start_time": "2020-08-08T10:09:26.362095Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(smclr.model.state_dict(), \"ImageModelShim-smclr.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:35:19.780736Z",
     "start_time": "2020-07-14T09:51:33.489826Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-2)\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "model = augment_training(\"resnet50_ssl\", epochs = 10, batch_size = 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T11:11:22.894259Z",
     "start_time": "2020-07-14T10:44:24.560696Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sgd_params = dict(lr=2e-5, momentum=0.9, dampening=0, weight_decay=1e-4, nesterov=False)\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "contrastive_training(\"resnet50_ssl\", epochs = 1, batch_size = 64, \n",
    "                     cache_images = False, dev = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T11:26:04.045393Z",
     "start_time": "2020-07-14T11:26:03.803350Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -ltrah | grep resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "822px",
    "left": "0px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
