{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T12:07:36.328359Z",
     "start_time": "2020-08-07T12:07:33.480800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import random\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, random_word_mask, my_collate\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import NegativeSamplingDataset, ImageFolderDataset, ZipDatasets\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "from facebook_hateful_memes_detector.utils import get_vgg_face_model, get_torchvision_classification_models, init_fc\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T12:07:36.338598Z",
     "start_time": "2020-08-07T12:07:36.330064Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T12:07:36.350071Z",
     "start_time": "2020-08-07T12:07:36.340270Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_easy = transforms.Compose([\n",
    "    transforms.RandomGrayscale(p=0.25),\n",
    "    transforms.RandomHorizontalFlip(p=0.25),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224,\n",
    "                                                          0.225]),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.05, 0.2))\n",
    "])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomPerspective(distortion_scale=0.25, p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomRotation(15),\n",
    "        DefinedRotation(90),\n",
    "        transforms.RandomAffine(\n",
    "            0,\n",
    "            translate=(0.25, 0.25),\n",
    "            scale=(0.6, 1.4),\n",
    "            shear=None,\n",
    "        ),\n",
    "        transforms.RandomResizedCrop(480, scale=(0.6, 1.0)) # Zoom in\n",
    "    ]),  \n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224,\n",
    "                                                          0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.05, 0.2))\n",
    "])\n",
    "\n",
    "# AveragePooling MaxPooling Spatter Cutout CoarseDropout AdditiveGaussianNoise\n",
    "\n",
    "def torch_vectorize(fn):\n",
    "    def vfn(elements):\n",
    "        elements = [fn(e) for e in elements]\n",
    "        return torch.stack(elements).type(torch.cuda.HalfTensor)\n",
    "    return vfn\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T12:07:36.356732Z",
     "start_time": "2020-08-07T12:07:36.351565Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=1e-4, momentum=0.9, dampening=0, weight_decay=1e-4, nesterov=False)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "augmentation_weights = {\"None\": 1.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented/Masked Image same as Original Image - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.290243Z",
     "start_time": "2020-07-14T10:43:53.284899Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "class ImageVectorizer(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        images = images.type(torch.cuda.HalfTensor)\n",
    "        output = self.pool(self.model(images)).squeeze()\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.298600Z",
     "start_time": "2020-07-14T10:43:53.291631Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_training(model_name, epochs = 10, batch_size = 256):\n",
    "    im_model = get_torchvision_classification_models(model_name, finetune=True)[0]\n",
    "    dataset_org = torch.utils.data.ConcatDataset([ImageFolderDataset(\"../data/img/\", image_transform=get_image2torchvision_transforms()),\n",
    "                                                  ImageFolderDataset(\"../data/img/\", image_transform=get_image2torchvision_transforms())])\n",
    "    dataset_mod = torch.utils.data.ConcatDataset([ImageFolderDataset(\"../data/img/\", image_transform=preprocess_easy),\n",
    "                                                  ImageFolderDataset(\"../data/img/\", image_transform=preprocess)])\n",
    "\n",
    "    zipped_dataset = ZipDatasets([dataset_org, dataset_mod])\n",
    "    \n",
    "    model_fn = model_builder(ImageVectorizer,\n",
    "                         dict(model=im_model),\n",
    "                         per_param_opts_fn=lr_strategy,\n",
    "                         optimiser_class=optimizer,\n",
    "                         optimiser_params=optimizer_params)\n",
    "\n",
    "    model, optim = model_fn()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _ = train_for_augment_similarity(model,\n",
    "                                     optim,\n",
    "                                     scheduler_init_fn,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     zipped_dataset,\n",
    "                                     augment_method=lambda x: x,\n",
    "                                     model_call_back=None,\n",
    "                                     accumulation_steps=1,\n",
    "                                     collate_fn=None,\n",
    "                                     plot=True)\n",
    "    torch.save(model.model.state_dict(), \"%s-augsim.pth\" % model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:53.303541Z",
     "start_time": "2020-07-14T10:43:53.300543Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(model.model.state_dict(), \"resnet18-augsim.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Training / Distinguish between positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:54.610864Z",
     "start_time": "2020-07-14T10:43:54.601079Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "class ImageDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, model, dims):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        layer1 = nn.Linear(dims * 2, dims)\n",
    "        init_fc(layer1, \"leaky_relu\")\n",
    "        layer2 = nn.Linear(dims, 2)\n",
    "        init_fc(layer2, \"linear\")\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.2), nn.LayerNorm(dims * 2), \n",
    "                                        layer1, nn.LeakyReLU(), GaussianNoise(0.5), layer2)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        anchor, other, labels = data\n",
    "        anchor = anchor.type(torch.cuda.HalfTensor)\n",
    "        other = other.type(torch.cuda.HalfTensor)\n",
    "        \n",
    "        anchor_out = self.pool(self.model(anchor)).squeeze()\n",
    "        other_out = self.pool(self.model(other)).squeeze()\n",
    "        features = torch.cat([anchor_out, other_out], 1)\n",
    "        logits = self.classifier(features).squeeze()\n",
    "        loss = self.loss(logits, labels.to(get_device()).long())\n",
    "        logits = torch.softmax(logits, dim=1)\n",
    "        return logits, features, features, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:43:54.872234Z",
     "start_time": "2020-07-14T10:43:54.861180Z"
    }
   },
   "outputs": [],
   "source": [
    "def contrastive_training(model_name,\n",
    "                         epochs=1,\n",
    "                         batch_size=256,\n",
    "                         cache_images=True,\n",
    "                         dev=True):\n",
    "    optimizer = sgd\n",
    "    optimizer_params = sgd_params\n",
    "    im_model, shapes = get_torchvision_classification_models(\"%s-augsim\" %\n",
    "                                                             model_name,\n",
    "                                                             finetune=True)\n",
    "    model_fn = model_builder(ImageDiscriminator,\n",
    "                             dict(model=im_model, dims=shapes[0]),\n",
    "                             per_param_opts_fn=lr_strategy,\n",
    "                             optimiser_class=optimizer,\n",
    "                             optimiser_params=optimizer_params)\n",
    "\n",
    "    model, optim = model_fn()\n",
    "\n",
    "    if cache_images:\n",
    "        orig = ImageFolderDataset(\n",
    "            \"../data/img/\",\n",
    "            image_transform=get_image2torchvision_transforms(),\n",
    "            cache_images=True)\n",
    "        mods = ImageFolderDataset.from_images(orig.images,\n",
    "                                              image_transform=preprocess)\n",
    "        dataset = torch.utils.data.ConcatDataset([orig, mods])\n",
    "    else:\n",
    "        orig = ImageFolderDataset(\n",
    "            \"../data/img/\",\n",
    "            image_transform=get_image2torchvision_transforms(),\n",
    "            cache_images=False)\n",
    "        mods = ImageFolderDataset(\"../data/img/\",\n",
    "                                  image_transform=preprocess,\n",
    "                                  cache_images=False)\n",
    "        dataset = torch.utils.data.ConcatDataset([orig, mods])\n",
    "\n",
    "    if dev:\n",
    "        dataset, _ = torch.utils.data.random_split(dataset, [6_000, 14_000])\n",
    "        \n",
    "    dataset = NegativeSamplingDataset(dataset, negative_proportion=4)\n",
    "\n",
    "    train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "        dataset, [int(0.8 * len(dataset)),\n",
    "                  int(0.2 * len(dataset))])\n",
    "\n",
    "    train_losses, learning_rates = train(model,\n",
    "                                         optim,\n",
    "                                         scheduler_init_fn,\n",
    "                                         batch_size,\n",
    "                                         epochs,\n",
    "                                         train_dataset,\n",
    "                                         model_call_back=None,\n",
    "                                         accumulation_steps=1,\n",
    "                                         validation_strategy=None,\n",
    "                                         plot=True,\n",
    "                                         collate_fn=None,\n",
    "                                         sampling_policy=None,\n",
    "                                         class_weights=None)\n",
    "    metrics = [\"map\", \"acc\", \"auc\"]\n",
    "    val_metrics = validate(model,\n",
    "                           batch_size,\n",
    "                           validation_dataset,\n",
    "                           collate_fn=None)[0]\n",
    "    if not dev:\n",
    "        torch.save(model.model.state_dict(), \"%s-contrastive.pth\" % model_name)\n",
    "    return dict(val=dict(zip(metrics, val_metrics)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR\n",
    "\n",
    "- Try Non overlapping image part Aug1, Aug2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T13:21:02.583098Z",
     "start_time": "2020-08-07T12:33:21.121822Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_vec = torch_vectorize(preprocess)\n",
    "preprocess_easy_vec = torch_vectorize(preprocess_easy)\n",
    "from facebook_hateful_memes_detector.utils import SimCLR\n",
    "from facebook_hateful_memes_detector.utils.ImageModelShims import ImageModelShim\n",
    "\n",
    "model = ImageModelShim(dropout=0.1, gaussian_noise=0.0)\n",
    "smclr = SimCLR(model, 768, 256, 0.1, preprocess_vec, preprocess_easy_vec)\n",
    "dataset = ImageFolderDataset(\"../data/img/\",\n",
    "                             image_transform=lambda x: x,\n",
    "                             cache_images=False)\n",
    "def collate_fn(batch):\n",
    "    # Create and return sample list with proper name and type set\n",
    "    return list(batch)\n",
    "\n",
    "lr_strategy = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"resnet_model\": {\n",
    "            \"finetune\": False,\n",
    "            \"7\": {\n",
    "                \"finetune\": False,\n",
    "            },\n",
    "            \"8\": {\n",
    "                \"finetune\": False,\n",
    "            }\n",
    "        },\n",
    "        \"vgg_model\": {\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4,\n",
    "                        betas=(0.9, 0.98),\n",
    "                        eps=1e-08,\n",
    "                        weight_decay=1e-2)\n",
    "\n",
    "smclr = smclr.to(get_device())\n",
    "_ = group_wise_finetune(smclr, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(smclr, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates = train(smclr,\n",
    "                                     optimizer,\n",
    "                                     scheduler_init_fn,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     dataset,\n",
    "                                     model_call_back=None,\n",
    "                                     accumulation_steps=1,\n",
    "                                     plot=True,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     sampling_policy=None,\n",
    "                                     class_weights=None)\n",
    "\n",
    "smclr.plot_loss_acc_hist()\n",
    "smclr.test_accuracy(batch_size, dataset, collate_fn=collate_fn)\n",
    "\n",
    "##\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-5,\n",
    "                        betas=(0.9, 0.98),\n",
    "                        eps=1e-08,\n",
    "                        weight_decay=1e-2)\n",
    "\n",
    "lr_strategy = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"resnet_model\": {\n",
    "            \"finetune\": False,\n",
    "            \"7\": {\n",
    "                \"finetune\": True,\n",
    "            },\n",
    "            \"8\": {\n",
    "                \"finetune\": True,\n",
    "            }\n",
    "        },\n",
    "        \"vgg_model\": {\n",
    "            \"0\": {\n",
    "                \"feat_extract\": {\n",
    "                   \"finetune\": True, \n",
    "                }\n",
    "            },\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "_ = group_wise_finetune(smclr, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(smclr, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates = train(smclr,\n",
    "                                     optimizer,\n",
    "                                     scheduler_init_fn,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     dataset,\n",
    "                                     model_call_back=None,\n",
    "                                     accumulation_steps=1,\n",
    "                                     plot=True,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     sampling_policy=None,\n",
    "                                     class_weights=None)\n",
    "\n",
    "smclr.plot_loss_acc_hist()\n",
    "acc = smclr.test_accuracy(batch_size, dataset, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:21:58.346231Z",
     "start_time": "2020-08-06T19:21:58.338386Z"
    }
   },
   "outputs": [],
   "source": [
    "smclr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T10:35:19.780736Z",
     "start_time": "2020-07-14T09:51:33.489826Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-2)\n",
    "optimizer = adam\n",
    "optimizer_params = adam_params\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "model = augment_training(\"resnet50_ssl\", epochs = 10, batch_size = 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T11:11:22.894259Z",
     "start_time": "2020-07-14T10:44:24.560696Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sgd_params = dict(lr=2e-5, momentum=0.9, dampening=0, weight_decay=1e-4, nesterov=False)\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 100,\n",
    "        \"7\": {\"lr\": optimizer_params[\"lr\"]/10},\n",
    "        \"8\": {\"lr\": optimizer_params[\"lr\"]},\n",
    "        \"finetune\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "contrastive_training(\"resnet50_ssl\", epochs = 1, batch_size = 64, \n",
    "                     cache_images = False, dev = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T11:26:04.045393Z",
     "start_time": "2020-07-14T11:26:03.803350Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -ltrah | grep resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "822px",
    "left": "0px",
    "top": "111.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
