{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:39:55.458563Z",
     "start_time": "2020-08-23T19:39:51.725277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, my_collate, clean_memory\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import MarianMTModel, MarianTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:39:55.577132Z",
     "start_time": "2020-08-23T19:39:55.463442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text\n",
       "0  42953   its their character not their color that matters\n",
       "1  23058  don't be afraid to love again everyone is not ...\n",
       "2  13894                           putting bows on your pet\n",
       "3  37408  i love everything and everybody! except for sq...\n",
       "4  82403  everybody loves chocolate chip cookies, even h..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=None, train_image_transform=None, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = False, dev=False, test_dev=True,\n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=False,)\n",
    "df = pd.concat((data[\"train\"][[\"id\", \"text\"]], data[\"dev\"][[\"id\", \"text\"]], data[\"test\"][[\"id\", \"text\"]]))\n",
    "df.shape\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:39:55.599651Z",
     "start_time": "2020-08-23T19:39:55.579466Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_translator(lang_models, model_type=\"huggingface\"):\n",
    "    \n",
    "    if model_type==\"huggingface\":\n",
    "        forward_model, backward_model = lang_models[\"fwd\"], lang_models[\"inv\"]\n",
    "        tokenizer = MarianTokenizer.from_pretrained(forward_model)\n",
    "        model = MarianMTModel.from_pretrained(forward_model)\n",
    "        model = model.to(get_device())\n",
    "        model = model.eval()\n",
    "        state = dict(fwd=(tokenizer, model))\n",
    "        tokenizer = MarianTokenizer.from_pretrained(backward_model)\n",
    "        model = MarianMTModel.from_pretrained(backward_model)\n",
    "        model = model.to(get_device())\n",
    "        model = model.eval()\n",
    "        state[\"inv\"] = (tokenizer, model)\n",
    "    elif model_type==\"pytorch\":\n",
    "        forward_model, backward_model = lang_models[\"fwd\"], lang_models[\"inv\"]\n",
    "        if \"fwd_checkpoint_file\" in lang_models:\n",
    "            model = torch.hub.load('pytorch/fairseq', forward_model, \n",
    "                                   tokenizer='moses', bpe='fastbpe', checkpoint_file=lang_models[\"fwd_checkpoint_file\"])\n",
    "            \n",
    "        else:\n",
    "            model = torch.hub.load('pytorch/fairseq', forward_model, tokenizer='moses', bpe='fastbpe')\n",
    "            \n",
    "            \n",
    "        if \"inv_checkpoint_file\" in lang_models:\n",
    "            backward_model = torch.hub.load('pytorch/fairseq', backward_model, \n",
    "                                            tokenizer='moses', bpe='fastbpe', checkpoint_file=lang_models[\"inv_checkpoint_file\"])\n",
    "        else:\n",
    "            backward_model = torch.hub.load('pytorch/fairseq', backward_model, tokenizer='moses', bpe='fastbpe')\n",
    "        model = model.to(get_device())\n",
    "        model = model.eval()\n",
    "        backward_model = backward_model.to(get_device())\n",
    "        backward_model = backward_model.eval()\n",
    "        state = dict(fwd=model, inv=backward_model)\n",
    "        \n",
    "    def translate(text):\n",
    "        texts = [text]\n",
    "        if model_type==\"huggingface\":\n",
    "            fwd_tokenizer, fwd_model = state[\"fwd\"]\n",
    "            inv_tokenizer, inv_model = state[\"inv\"]\n",
    "            lang_codes = fwd_tokenizer.supported_language_codes\n",
    "            if \"ROMANCE\" in forward_model:\n",
    "                lang_codes = ['>>fr<<', '>>es<<', '>>it<<', '>>pt<<', '>>ro<<', '>>ca<<', '>>gl<<', '>>la<<', '>>wa<<', '>>fur<<', '>>oc<<', '>>sc<<', '>>an<<', '>>frp<<',]\n",
    "                better_lang_codes = ['>>fr<<', '>>es<<', '>>it<<', '>>pt<<', '>>ca<<', '>>fur<<', '>>oc<<', '>>sc<<', '>>an<<', '>>frp<<']\n",
    "                lang_codes = better_lang_codes\n",
    "            if \"CELTIC\" in forward_model:\n",
    "                lang_codes = ['>>ga<<']\n",
    "            if len(lang_codes) > 0:\n",
    "                texts = [t for text in texts for t in [lang+\" \"+text for lang in lang_codes]]\n",
    "            batch = fwd_tokenizer.prepare_translation_batch(texts)\n",
    "            for k, v in batch.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    v = v.to(get_device())\n",
    "                    batch[k] = v\n",
    "            translated = fwd_model.generate(**batch)\n",
    "            fwd_translations = [fwd_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "            inv_batch = inv_tokenizer.prepare_translation_batch(fwd_translations)\n",
    "            for k, v in inv_batch.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    v = v.to(get_device())\n",
    "                    inv_batch[k] = v\n",
    "            translated = inv_model.generate(**inv_batch)\n",
    "            tgt_text = [inv_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "            clean_memory()\n",
    "            return tgt_text\n",
    "        elif model_type==\"pytorch\":\n",
    "            intermediate = state[\"fwd\"].translate(text)\n",
    "            res = state[\"inv\"].translate(intermediate)\n",
    "            clean_memory()\n",
    "            return [res]\n",
    "    return translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:39:55.606429Z",
     "start_time": "2020-08-23T19:39:55.602061Z"
    }
   },
   "outputs": [],
   "source": [
    "fox = \"The quick brown fox jumps over the lazy dog.\"\n",
    "cats = \"The cat sat on the front porch sipping a pint of milk.\"\n",
    "text = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.'\n",
    "text_long = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments, monopolized the financial systems of nations instigated wars and intentionally created chaos in societies? the jews have mass murdered millions of non- jews over the centuries they have seized control of the media so you will never find out study the history of the jews!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:39:56.610115Z",
     "start_time": "2020-08-23T19:39:56.606434Z"
    }
   },
   "outputs": [],
   "source": [
    "hg_en_ru = dict(fwd='Helsinki-NLP/opus-mt-en-ru', inv='Helsinki-NLP/opus-mt-ru-en')\n",
    "hg_en_de = dict(fwd='Helsinki-NLP/opus-mt-en-de', inv='Helsinki-NLP/opus-mt-de-en')\n",
    "hg_en_celtic = dict(fwd='Helsinki-NLP/opus-mt-en-CELTIC', inv='sshleifer/opus-mt-CELTIC-en')\n",
    "hg_en_romance = dict(fwd='Helsinki-NLP/opus-mt-en-ROMANCE', inv='Helsinki-NLP/opus-mt-ROMANCE-en')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:38:56.169097Z",
     "start_time": "2020-08-23T19:38:34.285610Z"
    }
   },
   "outputs": [],
   "source": [
    "fox = \"The quick brown fox jumps over the lazy dog.\"\n",
    "cats = \"The cat sat on the front porch sipping a pint of milk.\"\n",
    "text = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.'\n",
    "text_long = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments, monopolized the financial systems of nations instigated wars and intentionally created chaos in societies? the jews have mass murdered millions of non- jews over the centuries they have seized control of the media so you will never find out study the history of the jews!'\n",
    "translate = build_translator(hg_en_ru)\n",
    "translate(fox)\n",
    "translate(cats)\n",
    "translate(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:40:09.534093Z",
     "start_time": "2020-08-23T19:40:09.528296Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pt_en_de_1 = dict(fwd='transformer.wmt19.en-de.single_model', inv='transformer.wmt19.de-en.single_model')\n",
    "pt_en_de_2 = dict(fwd='transformer.wmt19.en-de.single_model', inv='transformer.wmt19.de-en', inv_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt')\n",
    "\n",
    "pt_en_de_3 = dict(fwd='transformer.wmt19.en-de', fwd_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt', \n",
    "                  inv='transformer.wmt19.de-en.single_model')\n",
    "pt_en_de_4 = dict(fwd='transformer.wmt19.en-de', fwd_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt', \n",
    "                  inv='transformer.wmt19.de-en', inv_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt')\n",
    "\n",
    "pt_en_de_5 = dict(fwd='transformer.wmt16.en-de', inv='transformer.wmt19.de-en.single_model')\n",
    "pt_en_de_6 = dict(fwd='transformer.wmt16.en-de', inv='transformer.wmt19.de-en', inv_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt')\n",
    "\n",
    "pt_en_de_7 = dict(fwd='conv.wmt17.en-de', inv='transformer.wmt19.de-en.single_model')\n",
    "pt_en_de_8 = dict(fwd='conv.wmt17.en-de', inv='transformer.wmt19.de-en', inv_checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt')\n",
    "\n",
    "pt_en_ru = dict(fwd='transformer.wmt19.en-ru.single_model', inv='transformer.wmt19.ru-en.single_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:34:06.842224Z",
     "start_time": "2020-08-23T19:23:38.633974Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ahemf/.cache/torch/hub/pytorch_fairseq_master\n",
      "100%|██████████| 2193287384/2193287384 [00:43<00:00, 50676906.93B/s]\n",
      "Using cache found in /home/ahemf/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The speedy brown fox skips over the lazy dog.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['The cat sat on the front pork and drank a pint of milk.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['have you ever studied the history of the jews? did you know that as a tribe, they have always gagged infiltrated governments.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export CURL_CA_BUNDLE=\"\"\n",
    "import os\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "translate = build_translator(pt_en_de_5, model_type=\"pytorch\")\n",
    "translate(fox)\n",
    "translate(cats)\n",
    "translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:23:31.550318Z",
     "start_time": "2020-08-24T05:23:18.693451Z"
    }
   },
   "outputs": [],
   "source": [
    "translate = build_translator(hg_en_celtic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:23:31.555546Z",
     "start_time": "2020-08-24T05:23:31.552570Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-24T05:23:25.160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7690e285b3b4637a8a0db92a78b957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    keys = row[1].index.values\n",
    "    values = row[1].values\n",
    "    d = dict(zip(keys, values))\n",
    "    t = translate(d[\"text\"])\n",
    "    if isinstance(translate, (list, tuple)):\n",
    "        r = [(d[\"id\"],ts) for ts in t]\n",
    "        results.extend(r)\n",
    "    else:\n",
    "        results.append((d[\"id\"], t))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-24T05:23:36.123Z"
    }
   },
   "outputs": [],
   "source": [
    "translate = build_translator(hg_en_romance)\n",
    "\n",
    "for row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    keys = row[1].index.values\n",
    "    values = row[1].values\n",
    "    d = dict(zip(keys, values))\n",
    "    t = translate(d[\"text\"])\n",
    "    if isinstance(translate, (list, tuple)):\n",
    "        r = [(d[\"id\"],ts) for ts in t]\n",
    "        results.extend(r)\n",
    "    else:\n",
    "        results.append((d[\"id\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:16:07.717123Z",
     "start_time": "2020-08-24T05:16:07.713063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23058, [\"Don't be afraid to love again, everyone's not like your ex.\"])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:17:51.298070Z",
     "start_time": "2020-08-24T05:17:51.281715Z"
    }
   },
   "outputs": [],
   "source": [
    "rs = list(map(lambda x: (x[0],x[1][0]),results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:17:56.019212Z",
     "start_time": "2020-08-24T05:17:56.015324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42953, 'their character, not the color that matters.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:20:08.170452Z",
     "start_time": "2020-08-24T05:20:08.098841Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(rs, columns=[\"id\", \"text\"]).to_csv(os.path.join(get_global(\"models_dir\"),\"dab_1.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
