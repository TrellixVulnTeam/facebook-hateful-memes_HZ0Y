{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:06:19.771196Z",
     "start_time": "2020-10-09T19:06:11.998091Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import random\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "# set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"cache_dir\", \"/Users/ahemf/mygit/facebook-hateful-memes/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, random_word_mask, dict2sampleList, run_simclr, load_stored_params\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine, HalfSwap, get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.preprocessing import NegativeSamplingDataset, ImageFolderDataset, ZipDatasets\n",
    "from facebook_hateful_memes_detector.models.MultiModal.VilBertVisualBert import VilBertVisualBertModel\n",
    "from facebook_hateful_memes_detector.models.MultiModal import VilBertVisualBertModelV2, MLMSimCLR\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "from facebook_hateful_memes_detector.utils import get_vgg_face_model, get_torchvision_classification_models, init_fc, my_collate, merge_sample_lists\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "# Use mixup in SSL training, Use UDA maybe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:06:19.971905Z",
     "start_time": "2020-10-09T19:06:19.773193Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_preprocess_text():\n",
    "    char_level = {\"keyboard\": 0.1, \"char_substitute\": 0.4, \"char_insert\": 0.2, \"char_swap\": 0.2, \n",
    "                  \"ocr\": 0.0, \"char_delete\": 0.1}\n",
    "    char_level = TextAugment([0.1, 0.4, 0.5], char_level)\n",
    "    word_level = {\"split\": 0.2,\n",
    "                 \"stopword_insert\": 0.0, \"word_join\": 0.2, \"punctuation_continue\": 0.5}\n",
    "    word_level = TextAugment([0.1, 0.4, 0.5], word_level, \n",
    "                             fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "    sentence_level = {\"text_rotate\": 0.0, \"sentence_shuffle\": 0.0, # \"glove_twitter\": 0.75,\"word_cutout\": 0.5,\n",
    "                      \"one_third_cut\": 0.25, \"half_cut\":0.0, \"part_select\": 0.25, }\n",
    "    sentence_level = TextAugment([0.1, 0.9], sentence_level, # idf_file=\"/home/ahemf/cache/tfidf_terms.csv\"\n",
    "                                )\n",
    "    gibberish = {\"gibberish_insert\": 0.25, \"punctuation_insert\": 0.75, \n",
    "                 \"punctuation_replace\": 0.25, \"punctuation_strip\": 0.5,}\n",
    "    gibberish = TextAugment([0.25, 0.75], gibberish)\n",
    "    # translation = {\"dab\":1.0, \"punctuation_insert\": 0.01}\n",
    "    # translation = TextAugment([0.0, 1.0], translation, dab_file=\"/home/ahemf/cache/fdab.csv\")\n",
    "    def process(text, **kwargs):\n",
    "        if random.random() < 0.25:\n",
    "            text = sentence_level(text, **kwargs)\n",
    "        # else:\n",
    "            # text = translation(text, **kwargs)\n",
    "        text = word_level(text, **kwargs)\n",
    "        text = char_level(text, **kwargs)\n",
    "        text = gibberish(text, **kwargs)\n",
    "        return text\n",
    "    return process\n",
    "\n",
    "\n",
    "preprocess_text = get_preprocess_text()\n",
    "transforms_for_bbox_methods = get_transforms_for_bbox_methods()\n",
    "\n",
    "vectorized_text_processor = np.vectorize(preprocess_text)\n",
    "def vectorized_image_processor(images):\n",
    "    return [transforms_for_bbox_methods(i) for i in images]\n",
    "\n",
    "def augment_method(sampleList):\n",
    "    sampleList = dict2sampleList(sampleList, device=get_device())\n",
    "    sampleList = sampleList.copy()\n",
    "    sampleList.image = vectorized_image_processor(sampleList.original_image)\n",
    "    sampleList.text = vectorized_text_processor(sampleList.original_text)\n",
    "    sampleList.mixup = [False] * len(sampleList.text)\n",
    "    sampleList = sampleList.to(get_device())\n",
    "    return sampleList\n",
    "\n",
    "\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\",\n",
    "                    train_text_transform=None,\n",
    "                    train_image_transform=None,\n",
    "                    test_text_transform=None,\n",
    "                    test_image_transform=None,\n",
    "                    train_torchvision_pre_image_transform=None,\n",
    "                    test_torchvision_pre_image_transform=None,\n",
    "                    cache_images=False,\n",
    "                    use_images=True,\n",
    "                    dev=False,\n",
    "                    test_dev=True,\n",
    "                    keep_original_text=True,\n",
    "                    keep_original_image=True,\n",
    "                    keep_processed_image=False,\n",
    "                    keep_torchvision_image=False,\n",
    "                    train_mixup_config=None)\n",
    "\n",
    "\n",
    "data[\"test\"][\"label\"] = -1\n",
    "\n",
    "df = pd.concat((data[\"train\"],\n",
    "                data[\"dev\"], \n",
    "                data[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:06:19.982476Z",
     "start_time": "2020-10-09T19:06:19.975880Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = convert_dataframe_to_dataset(df, data[\"metadata\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:07:02.278067Z",
     "start_time": "2020-10-09T19:06:19.985437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding option config to projects/hateful_memes/configs/vilbert/from_cc.yaml\n",
      "Overriding option model to vilbert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_zoo to vilbert.finetuned.hateful_memes.from_cc_original\n",
      "Overriding option evaluation.predict to true\n",
      "Overriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
      "Overriding option model to visual_bert\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_zoo to visual_bert.finetuned.hateful_memes.from_coco\n",
      "Overriding option evaluation.predict to true\n",
      "LXRT encoder with 9 l_layers, 5 x_layers, and 5 r_layers.\n",
      "Overriding option config to projects/hateful_memes/configs/mmbt/with_features.yaml\n",
      "Overriding option model to mmbt\n",
      "Overriding option datasets to hateful_memes\n",
      "Overriding option run_type to val\n",
      "Overriding option checkpoint.resume_zoo to mmbt.hateful_memes.features\n",
      "Overriding option evaluation.predict to true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '/Users/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "Config '/Users/ahemf/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/utils/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N tokens Out =  164 Classifier Dims =  768 Matches embedding_dims:  True\n"
     ]
    }
   ],
   "source": [
    "model_params = dict(\n",
    "    model_name={\"lxmert\": dict(dropout=0.05, gaussian_noise=0.01), \n",
    "                \"vilbert\": dict(dropout=0.1, gaussian_noise=0.05), \n",
    "                \"visual_bert\": dict(dropout=0.1, gaussian_noise=0.05), \n",
    "                \"mmbt_region\": dict(dropout=0.1, gaussian_noise=0.05)},\n",
    "    num_classes=2,\n",
    "    gaussian_noise=0.0,\n",
    "    dropout=0.0,\n",
    "    word_masking_proba=0.125,\n",
    "    featurizer=\"pass\",\n",
    "    final_layer_builder=fb_1d_loss_builder,\n",
    "    internal_dims=768,\n",
    "    classifier_dims=768,\n",
    "    n_tokens_in=128,\n",
    "    n_tokens_out=128,\n",
    "    n_layers=0,\n",
    "    attention_drop_proba=0.0,\n",
    "    loss=\"focal\",\n",
    "    dice_loss_coef=0.0,\n",
    "    auc_loss_coef=0.0,\n",
    "    bbox_swaps=1,\n",
    "    bbox_copies=1,\n",
    "    bbox_deletes=0,\n",
    "    bbox_gaussian_noise=0.01,\n",
    "    finetune=False)\n",
    "\n",
    "model_class = VilBertVisualBertModelV2\n",
    "model = model_class(**model_params)\n",
    "model = model.to(get_device())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:07:02.735957Z",
     "start_time": "2020-10-09T19:07:02.279935Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "from facebook_hateful_memes_detector.models.MultiModal.VilBertVisualBertV2 import positive, negative\n",
    "mlm_model = MLMSimCLR(model, 0.1, {1: negative, 0: positive}, augment_method, augment_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T19:08:21.838586Z",
     "start_time": "2020-10-09T19:07:02.737792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocast =  False Epochs =  1 Divisor = 1 Examples = 10000 Batch Size =  1\n",
      "Training Samples =  10000 Weighted Sampling =  False Num Batches =  10000 Accumulation steps =  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e4b3ba6a8f441e88d8b075e6dd95d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75faadcfd2b243ce850b1273f8c2bc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=10000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [\"adverse thdis is how a ! ! ! snake ' ' ' s mouth looks from the inside , ! ! i think everything is clearnow\"] [\"resentment this is how a dnake ' ? ? s mo & th ooks from the inside ! ! ! , i thik everything is clar now\"]\n",
      "FeatureExtractor : Loaded Model...\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CheckpointFunctionBackward.forward: expected Variable (got tuple) for return value 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-525df67a0e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mparams_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_wise_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptimizer_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n\u001b[0m\u001b[1;32m     20\u001b[0m                                      \u001b[0mmodel_call_back\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                      sampling_policy=None, class_weights=None)\n",
      "\u001b[0;32m~/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/training/generic.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler_init_fn, batch_size, epochs, dataset, model_call_back, accumulation_steps, validation_strategy, plot, sampling_policy, collate_fn, class_weights, model_save_key, save_every, resume_most_recent_checkpoint)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fb/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/models/MultiModal/VilBertVisualBertV2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0minput_ids_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fb/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/models/MultiModal/VilBertVisualBertV2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sampleList)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mpre_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mpre_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mpre_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_logit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mpooled_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/models/MultiModal/VilBertVisualBertV2.py\u001b[0m in \u001b[0;36mget_vectors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vilbert_visual_bert_sample_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextSampleList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvilbert_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence_output_v\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence_output_v\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence_output_t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence_output_v\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence_output_t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mygit/facebook-hateful-memes/facebook_hateful_memes_detector/models/MultiModal/VilBertVisualBertV2.py\u001b[0m in \u001b[0;36mvilbert_processor\u001b[0;34m(self, sample_list, labels)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mclean_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# GPUtil.showUtilization()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         sequence_output_t, sequence_output_v, pooled_output_t, pooled_output_v, attention_weights = checkpoint(self.vilbert.model.bert, params[\"input_ids\"],\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_feature\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fb/lib/python3.8/site-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected keyword arguments: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: CheckpointFunctionBackward.forward: expected Variable (got tuple) for return value 4"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"vilbert\": {\"finetune\": True,},\n",
    "        \"visual_bert\": {\"finetune\": True,},\n",
    "        \"mmbt_region\": {\"finetune\": False,},\n",
    "        \"lxmert\": {\"finetune\": False,},\n",
    "    },\n",
    "    \"mlms\": {\"finetune\": True},\n",
    "    \"simclr_layer\": {\"finetune\": True},\n",
    "}\n",
    "epochs = 1\n",
    "batch_size = 1\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "\n",
    "_ = group_wise_finetune(mlm_model, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(mlm_model, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n",
    "                                     model_call_back=None, accumulation_steps=4, plot=True,\n",
    "                                     sampling_policy=None, class_weights=None)\n",
    "\n",
    "\n",
    "\n",
    "mlm_model.plot_loss_acc_hist()\n",
    "mlm_model.test_accuracy(batch_size, dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T11:24:41.962482Z",
     "start_time": "2020-08-09T11:24:41.960247Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(mlm_model.state_dict(), \"lxmert-mlm-init.pth\")\n",
    "# mlm_model.load_state_dict(torch.load(\"lxmert-mlm-init.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T17:58:06.163460Z",
     "start_time": "2020-08-09T15:05:22.244073Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 5\n",
    "batch_size = 48\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "lr_strategy = {\n",
    "    \"model\": {\n",
    "        \"finetune\": True,\n",
    "        \"lr\": optimizer_params[\"lr\"]\n",
    "    },\n",
    "    \"mlm\": {\n",
    "        \"finetune\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "_ = group_wise_finetune(mlm_model, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(mlm_model, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n",
    "                                     model_call_back=None, accumulation_steps=5, plot=True,\n",
    "                                     sampling_policy=None, class_weights=None)\n",
    "\n",
    "\n",
    "\n",
    "mlm_model.plot_loss_acc_hist()\n",
    "acc = mlm_model.test_accuracy(batch_size, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:45:15.996131Z",
     "start_time": "2020-07-31T04:14:22.512090Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = mlm_model.test_accuracy(batch_size, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:12:59.352087Z",
     "start_time": "2020-08-09T19:12:51.954015Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(mlm_model.model.state_dict(), \"lxmert-mlm.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# AugSim\n",
    "- Combine both unimodal and bimodal augsim using `random.random`\n",
    "- Take hints from SimCLR\n",
    "- We can do Text x Image (TODO: CrissCrossDataset for Augsim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:18:06.984384Z",
     "start_time": "2020-08-09T19:18:06.364731Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "load_stored_params(model, \"lxmert-mlm.pth\")\n",
    "set_global(\"cache_allow_writes\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T19:18:22.043392Z",
     "start_time": "2020-08-09T19:18:22.039762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-5, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "optimizer_class = adamw\n",
    "optimizer_params = adamw_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T05:01:29.487245Z",
     "start_time": "2020-08-09T19:18:35.086830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "_ = group_wise_finetune(model, lr_strategy_model)\n",
    "params_conf, _ = group_wise_lr(model, lr_strategy_model)\n",
    "optim = optimizer_class(params_conf, **optimizer_params)\n",
    "\n",
    "_ = train_for_augment_similarity(model,\n",
    "                                 optim,\n",
    "                                 scheduler_init_fn,\n",
    "                                 batch_size,\n",
    "                                 epochs,\n",
    "                                 dataset,\n",
    "                                 augment_method=augment_method,\n",
    "                                 model_call_back=None,\n",
    "                                 collate_fn=my_collate,\n",
    "                                 accumulation_steps=4,\n",
    "                                 plot=True)\n",
    "# 0.001580, 0.000527\n",
    "# Try Augsim with L2 normed / LayerNormed vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T06:34:49.734072Z",
     "start_time": "2020-08-10T06:34:47.808602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lxmert-augsim.pth\")\n",
    "# model.load_state_dict(torch.load(\"lxmert-augsim.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR style or Differentiator\n",
    "- Combine Unimodal and Bimodal with probability\n",
    "- In unimodal differentiator we only change either text or image\n",
    "- Ability to use non-overlapping image sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.453139Z",
     "start_time": "2020-08-14T20:04:05.321942Z"
    }
   },
   "outputs": [],
   "source": [
    "load_stored_params(model, \"lxmert-smclr.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.459375Z",
     "start_time": "2020-08-14T20:04:06.455212Z"
    }
   },
   "outputs": [],
   "source": [
    "from facebook_hateful_memes_detector.utils import SimCLR\n",
    "\n",
    "def simclr_aug(sampleList):\n",
    "    sampleList = augment_method(sampleList.copy())\n",
    "    s2 = sampleList.copy()\n",
    "    s2.text = list(reversed(s2.text))\n",
    "    s = merge_sample_lists(sampleList, s2)\n",
    "    return s\n",
    "\n",
    "# set_global(\"cache_allow_writes\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:04:06.477539Z",
     "start_time": "2020-08-14T20:04:06.461220Z"
    }
   },
   "outputs": [],
   "source": [
    "smclr = SimCLR(model, 768, 256, 0.05, simclr_aug, simclr_aug)\n",
    "smclr = smclr.to(get_device())\n",
    "\n",
    "lr_strategy_pre = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"finetune\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "lr_strategy_post = {\n",
    "    \"finetune\": True,\n",
    "}\n",
    "\n",
    "pre_lr, post_lr = 5e-5, 5e-5\n",
    "pre_batch_size, post_batch_size = 256, 32\n",
    "pre_epochs, full_epochs = 2, 5\n",
    "collate_fn = my_collate\n",
    "\n",
    "def simclr_aug(sampleList):\n",
    "    sampleList = augment_method(sampleList.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-14T20:02:10.067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = run_simclr(smclr, dataset, dataset, lr_strategy_pre, lr_strategy_post, pre_lr, post_lr,\n",
    "           pre_batch_size, post_batch_size, pre_epochs, full_epochs,\n",
    "           collate_fn)\n",
    "\n",
    "res\n",
    "\n",
    "# 0.3268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T20:00:29.595925Z",
     "start_time": "2020-08-14T20:00:22.646123Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lxmert-smclr.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
