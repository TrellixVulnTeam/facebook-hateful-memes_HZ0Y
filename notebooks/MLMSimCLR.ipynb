{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:17:09.271374Z",
     "start_time": "2020-10-11T12:17:06.047166Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import random\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "# set_global(\"cache_dir\", \"/Users/ahemf/mygit/facebook-hateful-memes/cache\")\n",
    "set_global(\"dataloader_workers\", 8)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, random_word_mask, dict2sampleList, run_simclr, load_stored_params\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine, HalfSwap, get_transforms_for_bbox_methods\n",
    "from facebook_hateful_memes_detector.preprocessing import get_transforms_for_multiview\n",
    "from facebook_hateful_memes_detector.preprocessing import NegativeSamplingDataset, ImageFolderDataset, ZipDatasets\n",
    "from facebook_hateful_memes_detector.models.MultiModal.VilBertVisualBert import VilBertVisualBertModel\n",
    "from facebook_hateful_memes_detector.models.MultiModal import VilBertVisualBertModelV2, MLMSimCLR, MLMOnlyV2\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "from facebook_hateful_memes_detector.utils import get_vgg_face_model, get_torchvision_classification_models, init_fc, my_collate, merge_sample_lists\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "# Use mixup in SSL training, Use UDA maybe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:17:09.415581Z",
     "start_time": "2020-10-11T12:17:09.273234Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_preprocess_text():\n",
    "    char_level = {\"keyboard\": 0.1, \"char_substitute\": 0.4, \"char_insert\": 0.2, \"char_swap\": 0.2, \n",
    "                  \"ocr\": 0.0, \"char_delete\": 0.1}\n",
    "    char_level = TextAugment([0.1, 0.4, 0.5], char_level)\n",
    "    word_level = {\"split\": 0.2,\n",
    "                 \"stopword_insert\": 0.0, \"word_join\": 0.2, \"punctuation_continue\": 0.5}\n",
    "    word_level = TextAugment([0.1, 0.4, 0.5], word_level, \n",
    "                             fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "    sentence_level = {\"text_rotate\": 0.0, \"sentence_shuffle\": 0.0, # \"glove_twitter\": 0.75,\"word_cutout\": 0.5,\n",
    "                      \"one_third_cut\": 0.25, \"half_cut\":0.0, \"part_select\": 0.25, }\n",
    "    sentence_level = TextAugment([0.1, 0.9], sentence_level, # idf_file=\"/home/ahemf/cache/tfidf_terms.csv\"\n",
    "                                )\n",
    "    gibberish = {\"gibberish_insert\": 0.25, \"punctuation_insert\": 0.75, \n",
    "                 \"punctuation_replace\": 0.25, \"punctuation_strip\": 0.5,}\n",
    "    gibberish = TextAugment([0.25, 0.75], gibberish)\n",
    "    # translation = {\"dab\":1.0, \"punctuation_insert\": 0.01}\n",
    "    # translation = TextAugment([0.0, 1.0], translation, dab_file=\"/home/ahemf/cache/fdab.csv\")\n",
    "    def process(text, **kwargs):\n",
    "        if random.random() < 0.25:\n",
    "            text = sentence_level(text, **kwargs)\n",
    "        # else:\n",
    "            # text = translation(text, **kwargs)\n",
    "        text = word_level(text, **kwargs)\n",
    "        text = char_level(text, **kwargs)\n",
    "        text = gibberish(text, **kwargs)\n",
    "        return text\n",
    "    return process\n",
    "\n",
    "\n",
    "preprocess_text = get_preprocess_text()\n",
    "\n",
    "def get_views():\n",
    "    image_views = get_transforms_for_multiview()\n",
    "    def get_view_1():\n",
    "        augs = {\"keyboard\": 0.4, \"char_substitute\": 0.4, \"char_insert\": 0.2, \"char_swap\": 0.2, \n",
    "                      \"ocr\": 0.0, \"char_delete\": 0.1, \"gibberish_insert\": 0.1, \"punctuation_insert\": 0.75, \n",
    "                     \"punctuation_replace\": 0.25, \"punctuation_strip\": 0.5, \"word_join\": 0.2, \"punctuation_continue\": 0.5}\n",
    "        text_augs = TextAugment([0.1, 0.9,], augs)\n",
    "        imtrans = image_views[0]\n",
    "        vtp = np.vectorize(text_augs)\n",
    "        def vip(images):\n",
    "            return [imtrans(i) for i in images]\n",
    "\n",
    "        def aug(sampleList):\n",
    "            sampleList = dict2sampleList(sampleList, device=get_device())\n",
    "            sampleList = sampleList.copy()\n",
    "            sampleList.image = vip(sampleList.original_image)\n",
    "            sampleList.text = vtp(sampleList.original_text)\n",
    "            sampleList.mixup = [False] * len(sampleList.text)\n",
    "            sampleList = sampleList.to(get_device())\n",
    "            return sampleList\n",
    "        return aug\n",
    "    \n",
    "    def get_view_2():\n",
    "        augs = {\"keyboard\": 0.4, \"char_substitute\": 0.2, \"char_insert\": 0.2, \"char_swap\": 0.1, \n",
    "                      \"ocr\": 0.0, \"char_delete\": 0.1, \"gibberish_insert\": 0.0, \"punctuation_insert\": 0.75, \n",
    "                     \"punctuation_replace\": 0.5, \"punctuation_strip\": 0.5, \"word_join\": 0.3, \"punctuation_continue\": 0.5}\n",
    "        text_augs = TextAugment([0.2, 0.8,], augs)\n",
    "        imtrans = image_views[1]\n",
    "        vtp = np.vectorize(text_augs)\n",
    "        def vip(images):\n",
    "            return [imtrans(i) for i in images]\n",
    "\n",
    "        def aug(sampleList):\n",
    "            sampleList = dict2sampleList(sampleList, device=get_device())\n",
    "            sampleList = sampleList.copy()\n",
    "            sampleList.image = vip(sampleList.original_image)\n",
    "            sampleList.text = vtp(sampleList.original_text)\n",
    "            sampleList.mixup = [False] * len(sampleList.text)\n",
    "            sampleList = sampleList.to(get_device())\n",
    "            return sampleList\n",
    "        return aug\n",
    "    \n",
    "    def get_view_3():\n",
    "        imtrans = image_views[2]\n",
    "        def vip(images):\n",
    "            return [imtrans(i) for i in images]\n",
    "\n",
    "        def aug(sampleList):\n",
    "            sampleList = dict2sampleList(sampleList, device=get_device())\n",
    "            sampleList = sampleList.copy()\n",
    "            sampleList.image = vip(sampleList.original_image)\n",
    "            sampleList.text = sampleList.original_text\n",
    "            sampleList.mixup = [False] * len(sampleList.text)\n",
    "            sampleList = sampleList.to(get_device())\n",
    "            return sampleList\n",
    "        return aug\n",
    "    return [get_view_1(), get_view_2(), get_view_3()]\n",
    "\n",
    "data = get_datasets(data_dir=\"../data/\",\n",
    "                    train_text_transform=preprocess_text,\n",
    "                    train_image_transform=get_transforms_for_bbox_methods(),\n",
    "                    test_text_transform=None,\n",
    "                    test_image_transform=None,\n",
    "                    train_torchvision_pre_image_transform=None,\n",
    "                    test_torchvision_pre_image_transform=None,\n",
    "                    cache_images=True,\n",
    "                    use_images=True,\n",
    "                    dev=False,\n",
    "                    test_dev=True,\n",
    "                    keep_original_text=True,\n",
    "                    keep_original_image=True,\n",
    "                    keep_processed_image=True,\n",
    "                    keep_torchvision_image=False,\n",
    "                    train_mixup_config=None)\n",
    "\n",
    "\n",
    "data[\"test\"][\"label\"] = -1\n",
    "\n",
    "df = pd.concat((data[\"train\"],\n",
    "                data[\"dev\"], \n",
    "                data[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:19:41.723234Z",
     "start_time": "2020-10-11T12:17:09.417376Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = convert_dataframe_to_dataset(df, data[\"metadata\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:20:29.377369Z",
     "start_time": "2020-10-11T12:19:41.725247Z"
    }
   },
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    model_name={\"lxmert\": dict(dropout=0.05, gaussian_noise=0.01), \n",
    "                \"vilbert\": dict(dropout=0.1, gaussian_noise=0.05), \n",
    "                \"visual_bert\": dict(dropout=0.1, gaussian_noise=0.05), \n",
    "                \"mmbt_region\": dict(dropout=0.1, gaussian_noise=0.05)},\n",
    "    num_classes=2,\n",
    "    gaussian_noise=0.0,\n",
    "    dropout=0.0,\n",
    "    word_masking_proba=0.15,\n",
    "    featurizer=\"pass\",\n",
    "    final_layer_builder=fb_1d_loss_builder,\n",
    "    internal_dims=768,\n",
    "    classifier_dims=768,\n",
    "    n_tokens_in=128,\n",
    "    n_tokens_out=128,\n",
    "    n_layers=0,\n",
    "    attention_drop_proba=0.0,\n",
    "    loss=\"focal\",\n",
    "    dice_loss_coef=0.0,\n",
    "    auc_loss_coef=0.0,\n",
    "    bbox_swaps=1,\n",
    "    bbox_copies=1,\n",
    "    bbox_deletes=0,\n",
    "    bbox_gaussian_noise=0.01,\n",
    "    view_transforms=get_views(),\n",
    "    finetune=False)\n",
    "\n",
    "model_class = VilBertVisualBertModelV2\n",
    "model = model_class(**model_params)\n",
    "model = model.to(get_device())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:21:01.266227Z",
     "start_time": "2020-10-11T12:21:01.125014Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "from facebook_hateful_memes_detector.models.MultiModal.VilBertVisualBertV2 import positive, negative\n",
    "mlm_model = MLMOnlyV2(model, 0.1, {1: negative, 0: positive}, None)\n",
    "mlm_model = mlm_model.to(get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:24:06.169917Z",
     "start_time": "2020-10-11T12:21:02.875203Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lr_strategy = {\n",
    "    \"finetune\": True,\n",
    "    \"model\": {\n",
    "        \"vilbert\": {\"finetune\": False,},\n",
    "        \"visual_bert\": {\"finetune\": False,},\n",
    "        \"mmbt_region\": {\"finetune\": False,},\n",
    "        \"lxmert\": {\"finetune\": False,},\n",
    "    },\n",
    "    \"mlms\": {\"finetune\": True},\n",
    "}\n",
    "epochs = 1\n",
    "batch_size = 4\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer_params = dict(lr=1e-4, betas=(0.9, 0.98), eps=1e-08, weight_decay=1e-3)\n",
    "\n",
    "_ = group_wise_finetune(mlm_model, lr_strategy)\n",
    "params_conf, _ = group_wise_lr(mlm_model, lr_strategy)\n",
    "optimizer = optimizer_class(params_conf, **optimizer_params)\n",
    "train_losses, learning_rates, _ = train(mlm_model, optimizer, scheduler_init_fn, batch_size, epochs, dataset,\n",
    "                                     model_call_back=None, accumulation_steps=4, plot=True,\n",
    "                                     sampling_policy=None, class_weights=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T11:24:41.962482Z",
     "start_time": "2020-08-09T11:24:41.960247Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(mlm_model.state_dict(), \"lxmert-mlm-init.pth\")\n",
    "# mlm_model.load_state_dict(torch.load(\"lxmert-mlm-init.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T12:24:10.763795Z",
     "start_time": "2020-10-11T12:24:10.756416Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_stats = get_global(\"cache_stats\")\n",
    "cache_stats['get_img_details']\n",
    "cache_stats['get_lxmert_details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
